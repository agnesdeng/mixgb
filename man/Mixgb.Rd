% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Xgb-imputer.R
\docType{class}
\name{Mixgb}
\alias{Mixgb}
\title{XGBoost imputer: Multiple imputation through XGBoost}
\description{
Set up an XGBoost imputer object with specified hyperparameters and obtain multiply imputed datasets
}
\examples{
#use default
MIXGB <- Mixgb$new(data = nhanes3_newborn)
#obtain m multiply datasets without saving models
imputed.data <- MIXGB$impute(m = 5)

#obtain m multiply imputed datasets and save models for imputing new data later on
imputed.obj <- MIXGB$impute(m = 5, save.models = TRUE)
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{data}}{A data.frame or data.table with missing values.}

\item{\code{xgb.params}}{A list of XGBoost hyperparameters.}

\item{\code{nrounds}}{The maximum number of boosting iterations for XGBoost.}

\item{\code{early_stopping_rounds}}{An integer value \code{k}. XGBoost training will stop if the validation performance hasn't improved for \code{k} rounds.}

\item{\code{print_every_n}}{Print XGBoost evaluation information at every nth iteration if \code{verbose > 0}.}

\item{\code{verbose}}{Verbose setting for XGBoost training.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Mixgb$new()}}
\item \href{#method-impute}{\code{Mixgb$impute()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{Mixgb} object. This is used to set up an XGBoost imputer with chosen hyperparameters and verbose options
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Mixgb$new(
  data,
  xgb.params = list(max_depth = 6, gamma = 0.1, eta = 0.3, min_child_weight = 1,
    subsample = 1, colsample_bytree = 1, colsample_bylevel = 1, colsample_bynode = 1,
    nthread = 4, tree_method = "auto", gpu_id = 0, predictor = "auto"),
  nrounds = 50,
  early_stopping_rounds = 10,
  print_every_n = 10L,
  verbose = 0
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{A data.frame or data.table with missing values}

\item{\code{xgb.params}}{A list of XGBoost hyperparameters.}

\item{\code{nrounds}}{The maximum number of boosting iterations for XGBoost. Default: 50}

\item{\code{early_stopping_rounds}}{An integer value \code{k}. XGBoost training will stop if the validation performance hasn't improved for \code{k} rounds. Default: 10.}

\item{\code{print_every_n}}{Print XGBoost evaluation information at every nth iteration if \code{verbose > 0}.}

\item{\code{verbose}}{Verbose setting for XGBoost training: 0 (silent), 1 (print information) and 2 (print additional information). Default: 0}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
An XGBoost imputer object with chosen hyperparameters and verbose options
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-impute"></a>}}
\if{latex}{\out{\hypertarget{method-impute}{}}}
\subsection{Method \code{impute()}}{
Impute missing values with the pre-set XGBoost imputer and obtain multiply imputed datasets, with an option to save models for imputing new data later on.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Mixgb$impute(
  m = 5,
  maxit = 1,
  bootstrap = TRUE,
  pmm.type = "auto",
  pmm.k = 5,
  pmm.link = "prob",
  ordinalAsInteger = TRUE,
  initial.num = "normal",
  initial.int = "mode",
  initial.fac = "mode",
  save.models = FALSE,
  save.vars = NULL,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{m}}{The number of imputed datasets. Default: 5}

\item{\code{maxit}}{The number of imputation iterations. Default: 1}

\item{\code{bootstrap}}{Whether to use bootstrapping for multiple imputation. By default, \code{bootstrap = TRUE}. If \code{FALSE}, users are recommended to specify sampling-related hyperparameters of XGBoost to obtain imputations with adequate variability.}

\item{\code{pmm.type}}{The types of predictive mean matching (PMM). Possible values:
\itemize{
 \item \code{NULL}: Imputations without PMM;
 \item \code{0}: Imputations with PMM type 0;
 \item \code{1}: Imputations with PMM type 1;
 \item \code{2}: Imputations with PMM type 2;
 \item \code{"auto"} (Default): Imputations with PMM type 2 for numeric/integer variables; imputations without PMM for categorical variables.
}}

\item{\code{pmm.k}}{The number of donors for predictive mean matching. Default: 5}

\item{\code{pmm.link}}{The link for predictive mean matching binary variables
\itemize{
 \item \code{"prob"} (Default): use probabilities;
 \item \code{"logit"}: use logit values.
}}

\item{\code{ordinalAsInteger}}{Whether to convert ordinal factors to integers. The default setting \code{ordinalAsInteger = TRUE} can speed up the imputation process.}

\item{\code{initial.num}}{Initial imputation method for numeric type data:
\itemize{
 \item \code{"normal"} (Default);
 \item \code{"mean"};
 \item \code{"median"};
 \item \code{"mode"};
 \item \code{"sample"}.
}}

\item{\code{initial.int}}{Initial imputation method for integer type data:
\itemize{
 \item \code{"mode"} (Default);
 \item \code{"sample"}.
}}

\item{\code{initial.fac}}{Initial imputation method for factor type data:
\itemize{
 \item \code{"mode"} (Default);
 \item \code{"sample"}.
}}

\item{\code{save.models}}{Whether to save models for imputing new data later on. Default: \code{FALSE}}

\item{\code{save.vars}}{Response models for variables specified in \code{save.vars} will be saved for imputing new data. Can be a vector of names or indices. By default, \code{save.vars = NULL}, response models for variables with missing values will be saved. To save all models, please specify \code{save.vars = colnames(data)}.}

\item{\code{...}}{Extra arguments to pass to XGBoost}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
If \code{save.models = FALSE}, will return a list of \code{m} imputed datasets. If \code{save.models = TRUE}, will return an object with imputed datasets, saved models and parameters.
}
}
}
