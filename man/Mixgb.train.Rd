% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Xgb-train.R
\docType{class}
\name{Mixgb.train}
\alias{Mixgb.train}
\title{Multiple imputation through xgboost R6 class imputer object for training set}
\description{
Set up an xgboost imputer object with specified hyperparameters and then obtain an imputed object including multiple imputed datasets, saved models and parameters.
}
\examples{

## ------------------------------------------------
## Method `Mixgb.train$new`
## ------------------------------------------------

MIXGB=Mixgb.train$new(withNA.df)
MIXGB=Mixgb.train$new(withNA.df,nrounds=50,max_depth=6)

## ------------------------------------------------
## Method `Mixgb.train$impute`
## ------------------------------------------------

MIXGB=Mixgb.train$new(withNA.df)
mixgb.obj=MIXGB$impute(m = 5)
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Mixgb.train$new()}}
\item \href{#method-impute}{\code{Mixgb.train$impute()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{Mixgb} object. This is used to set up the multiple imputation imputer using xgboost.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Mixgb.train$new(
  data,
  nrounds = 50,
  max_depth = 6,
  gamma = 0.1,
  eta = 0.3,
  nthread = 4,
  early_stopping_rounds = 10,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1,
  pmm.k = 5,
  pmm.type = "auto",
  pmm.link = "logit",
  scale_pos_weight = 1,
  initial.imp = "random",
  tree_method = "auto",
  gpu_id = 0,
  predictor = "auto",
  print_every_n = 10L,
  verbose = 0
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{A data frame with missing values}

\item{\code{nrounds}}{max number of boosting iterations. Default: 50}

\item{\code{max_depth}}{maximum depth of the tree. Default: 6}

\item{\code{gamma}}{Default: 0.1}

\item{\code{eta}}{Default: 0.3}

\item{\code{nthread}}{Default: 4}

\item{\code{early_stopping_rounds}}{Default: 10,}

\item{\code{colsample_bytree}}{Default: 1}

\item{\code{min_child_weight}}{Default: 1}

\item{\code{subsample}}{Default: 1}

\item{\code{pmm.k}}{Default: 5}

\item{\code{pmm.type}}{Default: "auto" (used to be NULL)}

\item{\code{pmm.link}}{Default: "logit"}

\item{\code{scale_pos_weight}}{Default:1}

\item{\code{initial.imp}}{Default: "random"}

\item{\code{tree_method}}{Default: "auto" (can set "gpu_hist" for linux)}

\item{\code{gpu_id}}{Device ordinal. Default: 0}

\item{\code{predictor}}{The type of predictor algorithm to use. Default: "auto" (other options: "cpu_predictor","gpu_predictor")}

\item{\code{print_every_n}}{Default: 10L}

\item{\code{verbose}}{Default: 1}
}
\if{html}{\out{</div>}}
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{MIXGB=Mixgb.train$new(withNA.df)
MIXGB=Mixgb.train$new(withNA.df,nrounds=50,max_depth=6)
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-impute"></a>}}
\if{latex}{\out{\hypertarget{method-impute}{}}}
\subsection{Method \code{impute()}}{
Use the imputer to impute missing values and obtain multiple imputed datasets, saved training models and some parameters needed for future use.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Mixgb.train$impute(m = 5)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{m}}{the number of imputed datasets. Default: 5}
}
\if{html}{\out{</div>}}
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{MIXGB=Mixgb.train$new(withNA.df)
mixgb.obj=MIXGB$impute(m = 5)
}
\if{html}{\out{</div>}}

}

}
}
