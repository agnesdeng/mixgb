[{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://agnesdeng.github.io/mixgb/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://agnesdeng.github.io/mixgb/articles/Imputing-newdata.html","id":"impute-new-unseen-data-using-a-saved-imputer-object","dir":"Articles","previous_headings":"","what":"Impute new unseen data using a saved imputer object","title":"Imputing newdata with a saved mixgb imputer","text":"First, let us split nhanes3_newborn dataset training data test data. can use training data generate m imputed datasets save imputation models. achieve , users need set save.models = TRUE. default, imputation models variables missing values training data saved (save.vars = NULL). However, possible unseen data may missing values variables. thorough, users can save models variables setting save.vars = colnames(train.data). Note may take significantly longer requires training saving model variable. cases users confident certain variables missing values new data, advisable specify names indices variables save.vars rather saving models variables. save.models = TRUE, mixgb() return object containing following: imputed.data: list m imputed datasets training data XGB.models: list m sets XGBoost models variables specified save.vars. params: list parameters required imputing new data using impute_new() later . can access m imputed datasets saved imputer object using $imputed.data. impute new data saved imputer object, can use impute_new() function. Users can choose whether use new data initial imputation. default, information training data used initially impute missing data new dataset (initial.newdata = FALSE). , missing values new dataset imputed using saved models imputer object. process considerably faster involve rebuilding imputation models. PMM used mixgb(), predicted values missing entries new dataset matched donors training data. Additionally, users can set number donors used PMM imputing new data. default setting pmm.k = NULL indicates setting training object used. Similarly, users can set number imputed datasets m impute_new(). Note value less equal m value specified mixgb(). value specified, function use m value saved object. Users can also specify local directory parameter save.models.folder main function mixgb(). Models save JSON format calling xgb.save() internally. Saving XGBoost models way instead using saveRDS R recommended XGBoost. can ensure imputation models can still used later release XGBoost. users specify save.models.folder, return object include following: imputed.data: list m imputed datasets training data XGB.models: list directories m sets XGBoost models variables specified save.vars. params: list parameters required imputing new data using impute_new() later . XGB.save : parameter indicates whether XGB.models saved models directories saved models. mixgb.obj contain models , users need worry saving object via saveRDS(). later use, one can load object R impute new data.","code":"library(mixgb) data(\"nhanes3_newborn\") set.seed(2022) n <- nrow(nhanes3_newborn) idx <- sample(1:n, size = round(0.7 * n), replace = FALSE) train.data <- nhanes3_newborn[idx, ] test.data <- nhanes3_newborn[-idx, ] params <- list(   max_depth = 3,   subsample = 0.7,   nthread = 2 )  # obtain m imputed datasets for train.data and save imputation models mixgb.obj <- mixgb(data = train.data, m = 5, xgb.params = params, save.models = TRUE, save.vars = NULL) #> [21:36:45] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:45] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:45] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:45] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:46] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:47] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:48] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:50] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. train.imputed <- mixgb.obj$imputed.data # the 5th imputed dataset head(train.imputed[[5]]) #>    HSHSIZER HSAGEIR HSSEX DMARACER DMAETHNR DMARETHN BMPHEAD BMPRECUM BMPSB1 #> 1:        7       2     1        1        1        3    44.1     71.5    9.9 #> 2:        4       3     2        2        3        2    42.6     67.1    8.8 #> 3:        3       9     2        2        3        2    46.5     64.3    8.6 #> 4:        3       9     2        1        3        1    46.2     68.5   10.8 #> 5:        5       4     1        1        3        1    44.7     63.0    6.0 #> 6:        5      10     1        1        3        1    45.2     72.0    5.4 #>    BMPSB2 BMPTR1 BMPTR2 BMPWT DMPPIR HFF1 HYD1 #> 1:    8.8   13.2   13.0  8.65  1.701    2    1 #> 2:    8.8   13.3   12.2  8.70  0.102    2    1 #> 3:    8.0   10.4    9.2  8.00  0.359    1    3 #> 4:   10.0   16.6   16.0  8.98  0.561    1    3 #> 5:    5.8    9.0    9.0  7.60  2.379    2    1 #> 6:    5.4    9.2    9.4  9.00  2.173    2    2 test.imputed <- impute_new(object = mixgb.obj, newdata = test.data) test.imputed <- impute_new(object = mixgb.obj, newdata = test.data, initial.newdata = FALSE, pmm.k = 3, m = 4) # obtain m imputed datasets for train.data and save imputation models mixgb.obj <- mixgb(data = train.data, m = 5, save.models = TRUE, save.models.folder = \"C:/Users/.....\") saveRDS(object = mixgb.obj, file = \"C:/Users/.../mixgbimputer.rds\") mixgb.obj <- readRDS(file = \"C:/Users/.../mixgbimputer.rds\")  set.seed(2022) n <- nrow(nhanes3) idx <- sample(1:n, size = round(0.7 * n), replace = FALSE) train.data <- nhanes3[idx, ] test.data <- nhanes3[-idx, ]  test.imputed <- impute_new(object = mixgb.obj, newdata = test.data) test.imputed"},{"path":"https://agnesdeng.github.io/mixgb/articles/Using-mixgb.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"mixgb: Multiple Imputation Through XGBoost","text":"Mixgb offers scalable solution imputing large datasets using XGBoost, subsampling predictive mean matching. method utilizes capabilities XGBoost, highly efficient implementation gradient boosted trees, capture interactions non-linear relations automatically. Moreover, integrated subsampling predictive mean matching minimize bias reflect appropriate imputation variability. package supports various types variables offers flexible settings subsampling predictive mean matching. also include diagnostic tools evaluating quality imputed values.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/Using-mixgb.html","id":"impute-missing-values-with-mixgb","dir":"Articles","previous_headings":"","what":"Impute missing values with mixgb","title":"mixgb: Multiple Imputation Through XGBoost","text":"first load mixgb package nhanes3_newborn dataset, contains 16 variables various types (integer/numeric/factor/ordinal factor). 9 variables missing values. impute dataset, can use default settings. default number imputed datasets m = 5. Note need convert data dgCMatrix one-hot coding format. package automatically convert . Variables following types: numeric, integer, factor ordinal factor.","code":"library(mixgb) str(nhanes3_newborn) #> tibble [2,107 × 16] (S3: tbl_df/tbl/data.frame) #>  $ HSHSIZER: int [1:2107] 4 3 5 4 4 3 5 3 3 3 ... #>  $ HSAGEIR : int [1:2107] 2 5 10 10 8 3 10 7 2 7 ... #>  $ HSSEX   : Factor w/ 2 levels \"1\",\"2\": 2 1 2 2 1 1 2 2 2 1 ... #>  $ DMARACER: Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 2 1 1 1 2 1 2 2 ... #>  $ DMAETHNR: Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 3 3 3 3 3 3 3 ... #>  $ DMARETHN: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 3 2 1 1 1 2 1 2 2 ... #>  $ BMPHEAD : num [1:2107] 39.3 45.4 43.9 45.8 44.9 42.2 45.8 NA 40.2 44.5 ... #>   ..- attr(*, \"label\")= chr \"Head circumference (cm)\" #>  $ BMPRECUM: num [1:2107] 59.5 69.2 69.8 73.8 69 61.7 74.8 NA 64.5 70.2 ... #>   ..- attr(*, \"label\")= chr \"Recumbent length (cm)\" #>  $ BMPSB1  : num [1:2107] 8.2 13 6 8 8.2 9.4 5.2 NA 7 5.9 ... #>   ..- attr(*, \"label\")= chr \"First subscapular skinfold (mm)\" #>  $ BMPSB2  : num [1:2107] 8 13 5.6 10 7.8 8.4 5.2 NA 7 5.4 ... #>   ..- attr(*, \"label\")= chr \"Second subscapular skinfold (mm)\" #>  $ BMPTR1  : num [1:2107] 9 15.6 7 16.4 9.8 9.6 5.8 NA 11 6.8 ... #>   ..- attr(*, \"label\")= chr \"First triceps skinfold (mm)\" #>  $ BMPTR2  : num [1:2107] 9.4 14 8.2 12 8.8 8.2 6.6 NA 10.9 7.6 ... #>   ..- attr(*, \"label\")= chr \"Second triceps skinfold (mm)\" #>  $ BMPWT   : num [1:2107] 6.35 9.45 7.15 10.7 9.35 7.15 8.35 NA 7.35 8.65 ... #>   ..- attr(*, \"label\")= chr \"Weight (kg)\" #>  $ DMPPIR  : num [1:2107] 3.186 1.269 0.416 2.063 1.464 ... #>   ..- attr(*, \"label\")= chr \"Poverty income ratio\" #>  $ HFF1    : Factor w/ 2 levels \"1\",\"2\": 2 2 1 1 1 2 2 1 2 1 ... #>  $ HYD1    : Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 1 3 1 1 1 1 1 1 2 1 ... colSums(is.na(nhanes3_newborn)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>        0        0        0        0        0        0      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7        0 # use mixgb with default settings imputed.data <- mixgb(data = nhanes3_newborn, m = 5)"},{"path":"https://agnesdeng.github.io/mixgb/articles/Using-mixgb.html","id":"customize-imputation-settings","dir":"Articles","previous_headings":"Impute missing values with mixgb","what":"Customize imputation settings","title":"mixgb: Multiple Imputation Through XGBoost","text":"can also customize imputation settings: number imputed datasets m number imputation iterations maxit XGBoost hyperparameters verbose settings. xgb.params, nrounds, early_stopping_rounds, print_every_n verbose. Subsampling ratio. default, subsample = 0.7. Users can change value xgb.params argument. Predictive mean matching settings pmm.type, pmm.k pmm.link. Whether ordinal factors converted integer (imputation process may faster) ordinalAsInteger Whether use bootstrapping bootstrap Initial imputation methods different types variables initial.num, initial.int initial.fac. Whether save models imputing newdata save.models save.vars.","code":"# Use mixgb with chosen settings params <- list(   max_depth = 5,   subsample = 0.9,   nthread = 2,   tree_method = \"hist\" )  imputed.data <- mixgb(   data = nhanes3_newborn, m = 10, maxit = 2,   ordinalAsInteger = FALSE, bootstrap = FALSE,   pmm.type = \"auto\", pmm.k = 5, pmm.link = \"prob\",   initial.num = \"normal\", initial.int = \"mode\", initial.fac = \"mode\",   save.models = FALSE, save.vars = NULL,   xgb.params = params, nrounds = 200, early_stopping_rounds = 10, print_every_n = 10L, verbose = 0 )"},{"path":"https://agnesdeng.github.io/mixgb/articles/Using-mixgb.html","id":"tune-hyperparameters","dir":"Articles","previous_headings":"Impute missing values with mixgb","what":"Tune hyperparameters","title":"mixgb: Multiple Imputation Through XGBoost","text":"Imputation performance can affected hyperparameter settings. Although tuning large set hyperparameters may appear intimidating, often possible narrowing search space many hyperparameters correlated. package, function mixgb_cv() can used tune number boosting rounds - nrounds. default nrounds value XGBoost, users required specify value . default nrounds mixgb() 100. However, recommend using mixgb_cv() find optimal nrounds first. default, mixgb_cv() randomly choose incomplete variable response build XGBoost model variables explanatory variables using complete cases dataset. Therefore, run mixgb_cv() likely return different results. Users can also specify response covariates argument response select_features respectively. Let us just try setting nrounds = cv.results$best.nrounds mixgb() obtain 5 imputed datasets.","code":"params <- list(max_depth = 3, subsample = 0.7, nthread = 2) cv.results <- mixgb_cv(data = nhanes3_newborn, nrounds = 100, xgb.params = params, verbose = FALSE) cv.results$evaluation.log #>     iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std #>  1:    1        6.979132     0.02477682       6.981862     0.1395894 #>  2:    2        4.980510     0.02388748       4.991210     0.1466754 #>  3:    3        3.610892     0.02542558       3.622020     0.1546338 #>  4:    4        2.683989     0.02342666       2.710630     0.1643368 #>  5:    5        2.079606     0.02819653       2.118193     0.1684497 #>  6:    6        1.697816     0.02507535       1.751064     0.1733559 #>  7:    7        1.462659     0.02397902       1.529944     0.1734900 #>  8:    8        1.333645     0.02501703       1.416528     0.1722685 #>  9:    9        1.253979     0.02733306       1.349704     0.1636108 #> 10:   10        1.208826     0.02209953       1.319599     0.1634448 #> 11:   11        1.180906     0.02132700       1.302238     0.1572633 #> 12:   12        1.165138     0.02204102       1.299960     0.1544091 #> 13:   13        1.153183     0.02343314       1.302333     0.1536219 #> 14:   14        1.145831     0.02332107       1.309020     0.1514455 #> 15:   15        1.137217     0.02510718       1.309133     0.1511828 #> 16:   16        1.129401     0.02541954       1.307245     0.1488898 #> 17:   17        1.121943     0.02450859       1.308865     0.1473591 #> 18:   18        1.116408     0.02388570       1.317339     0.1473238 #> 19:   19        1.110756     0.02330111       1.320682     0.1471355 #> 20:   20        1.104374     0.02137588       1.321701     0.1480601 #> 21:   21        1.099340     0.01972492       1.323182     0.1447174 #> 22:   22        1.093946     0.01948428       1.325399     0.1440900 #>     iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std cv.results$response #> [1] \"BMPTR1\" cv.results$best.nrounds #> [1] 12 cv.results <- mixgb_cv(   data = nhanes3_newborn, nfold = 10, nrounds = 100, early_stopping_rounds = 1,   response = \"BMPHEAD\", select_features = c(\"HSAGEIR\", \"HSSEX\", \"DMARETHN\", \"BMPRECUM\", \"BMPSB1\", \"BMPSB2\", \"BMPTR1\", \"BMPTR2\", \"BMPWT\"), xgb.params = params, verbose = FALSE )  cv.results$best.nrounds #> [1] 23 imputed.data <- mixgb(data = nhanes3_newborn, m = 5, nrounds = cv.results$best.nrounds)"},{"path":"https://agnesdeng.github.io/mixgb/articles/Using-mixgb.html","id":"inspect-multiply-imputed-values","dir":"Articles","previous_headings":"","what":"Inspect multiply imputed values","title":"mixgb: Multiple Imputation Through XGBoost","text":"mixgb package provides following visual diagnostics functions: Single variable: plot_hist(), plot_box(), plot_bar() ; Two variables: plot_2num(), plot_2fac(), plot_1num1fac() ; Three variables: plot_2num1fac(), plot_1num2fac(). function return m+1 panels compare observed data m sets actual imputed values. details, please check vignette GitHub Visual diagnostics multiply imputed values.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"1. Introduction","title":"Visual diagnostics for multiply imputed values","text":"crucial assess plausibility imputations analysis. mixgb package provides several visual diagnostic functions using ggplot2 compare multiply imputed values versus observed data.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"inspecting-imputed-values","dir":"Articles > Web","previous_headings":"1. Introduction","what":"1.1 Inspecting imputed values","title":"Visual diagnostics for multiply imputed values","text":"demonstrate functions using nhanes3_newborn dataset. original data, almost missing values occurred numeric variables. seven observations missing binary factor variable HFF1. order visualize imputed values types variables, create extra missing values HSHSIZER (integer), HSAGEIR (integer), HSSEX (binary factor), DMARETHN (multiclass factor) HYD1 (Ordinal factor) missing completely random (MCAR) mechanism. impute dataset using mixgb() default settings. completion, list five imputed datasets assigned imputed.data. imputed dataset dimension original data. using function show_var(), can see multiply imputed values missing data given variable. function returns data.table m columns, represents set imputed values variable interest. Note output function includes imputed values missing entries specified variable.","code":"library(mixgb) colSums(is.na(nhanes3_newborn)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>        0        0        0        0        0        0      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7        0 withNA.df <- createNA(data = nhanes3_newborn, var.names = c(\"HSHSIZER\", \"HSAGEIR\", \"HSSEX\", \"DMARETHN\", \"HYD1\"), p = 0.1) colSums(is.na(withNA.df)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>      211      211      211        0        0      211      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7      211 imputed.data <- mixgb(data = withNA.df, m = 5) #> mixgb null start #> [21:37:00] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:00] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:00] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:00] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:00] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:01] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:02] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:03] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:04] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:05] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:06] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:07] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:08] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:08] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:08] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:08] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:08] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:09] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:10] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:10] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:10] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:10] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end show_var(imputation.list = imputed.data, var.name = \"BMPHEAD\", original.data = withNA.df) #>        m1   m2   m3   m4   m5 #>   1: 46.0 44.7 45.4 45.2 46.3 #>   2: 45.8 43.4 43.1 44.9 44.7 #>   3: 42.5 42.3 42.7 42.1 42.4 #>   4: 46.0 45.3 47.4 44.7 44.8 #>   5: 45.8 45.8 45.1 46.1 45.9 #>  ---                          #> 120: 44.6 46.0 45.8 44.3 46.0 #> 121: 44.0 44.2 44.9 45.4 44.2 #> 122: 40.2 41.6 40.9 40.8 41.8 #> 123: 43.0 44.3 44.0 44.0 44.0 #> 124: 44.8 47.7 46.0 43.7 45.0 show_var(imputation.list = imputed.data, var.name = \"HFF1\", original.data = withNA.df) #>    m1 m2 m3 m4 m5 #> 1:  2  2  2  2  2 #> 2:  1  1  1  1  1 #> 3:  2  2  1  2  2 #> 4:  1  1  1  1  1 #> 5:  2  2  2  2  1 #> 6:  2  2  2  2  1 #> 7:  1  1  1  1  1"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"visual-diagnostics-plots","dir":"Articles > Web","previous_headings":"","what":"2 Visual diagnostics plots","title":"Visual diagnostics for multiply imputed values","text":"mixgb package provides following visual diagnostics functions: Single variable: plot_hist(), plot_box(), plot_bar() ; Two variables: plot_2num(), plot_2fac(), plot_1num1fac() ; Three variables: plot_2num1fac(), plot_1num2fac(). function returns m+1 panels enable comparison observed data m sets imputed values missing data.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"single-variable","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots","what":"2.1 Single variable","title":"Visual diagnostics for multiply imputed values","text":"imputed values missing entries specified variable plotted panels m1 m5. error message displayed variable fully observed missing entries impute.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"numeric","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.1 Single variable","what":"2.1.1 Numeric","title":"Visual diagnostics for multiply imputed values","text":"can plot imputed numeric variable histogram boxplot. plot_hist(): plot histograms density curves. Histograms useful tool displaying distribution numeric data. Users can examine shapes histograms identify unusual patterns imputed values. data missing completely random (MCAR), expect distribution imputed values observed values. However, data missing random (MAR), distributions observed imputed values can quite different. Nevertheless, still worth plotting imputed data, unusual values may indicate imputation procedure unsatisfactory.  plot_box(): plot box plots overlaying data points. Users can use plot_box() compare median, lower upper quantiles imputed values observed values. plot also visually displays disparity counts observed missing values variable interest.","code":"plot_hist(   imputation.list = imputed.data, var.name = \"BMPHEAD\",   original.data = withNA.df ) plot_box(   imputation.list = imputed.data, var.name = \"BMPHEAD\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"factor","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.1 Single variable","what":"2.1.2 Factor","title":"Visual diagnostics for multiply imputed values","text":"plot_bar(): plot bar plots proportion level factor shown plot_bar().","code":"plot_bar(   imputation.list = imputed.data, var.name = \"HSSEX\",   original.data = withNA.df ) plot_bar(   imputation.list = imputed.data, var.name = \"DMARETHN\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"integer","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.1 Single variable","what":"2.1.3 Integer","title":"Visual diagnostics for multiply imputed values","text":"Users flexibility choose treat integer variables generating plot, can viewed either numeric factor variables. plot imputed integer variable, users can use one following functions based preferred representation: plot_hist(): plot histograms density curves plot_box(): plot box plot overlaying data points plot_bar(): plot bar plot (treat integer variable factor)","code":"plot_hist(   imputation.list = imputed.data, var.name = \"HSHSIZER\",   original.data = withNA.df ) plot_box(   imputation.list = imputed.data, var.name = \"HSHSIZER\",   original.data = withNA.df ) plot_bar(   imputation.list = imputed.data, var.name = \"HSHSIZER\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"ordinal-factor","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.1 Single variable","what":"2.1.4 Ordinal factor","title":"Visual diagnostics for multiply imputed values","text":"default, function mixgb() convert ordinal factors integers. Therefore, may simply plot ordinal factors factors (see Section 2.1.2). However, setting ordinalAsInteger = TRUE mixgb() may speed imputation process, users must decide whether transform back. choose convert ordinal factors integers prior imputation, imputed values must plotted integers (see Section 2.1.3).","code":"imputed.data2 <- mixgb(data = withNA.df, m = 5, ordinalAsInteger = TRUE) #> mixgb null start #> [21:37:15] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:16] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:17] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:18] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:19] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:20] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:21] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:22] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:23] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:24] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  plot_bar(   imputation.list = imputed.data2, var.name = \"HYD1\",   original.data = withNA.df ) plot_hist(   imputation.list = imputed.data2, var.name = \"HYD1\",   original.data = withNA.df ) plot_box(   imputation.list = imputed.data2, var.name = \"HYD1\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"two-variables","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots","what":"2.2 Two variables","title":"Visual diagnostics for multiply imputed values","text":"functions section visualizing multiply imputed values two variables require least one variables original dataset incomplete. imputed values shown panels m1 m5 originally missing one variables.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"two-numeric-variables","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.2 Two variables","what":"2.2.1 Two numeric variables","title":"Visual diagnostics for multiply imputed values","text":"can generate scatter plots two imputed numeric variables using plot_2num(). can specify x-axis variable var.x y-axis variable var.y. Users can choose plot shapes different types missing values setting shape = TRUE. recommend plotting shapes small datasets. default, shape = FALSE used expedite plotting process.  NA.condition represents following four types missing values. .observed: var.x andvar.y observed. appears first panel - Observed (Shape: diamond). .missing: Imputed values var.x var.y originally missing (Shape: circle); var.x.missing: Imputed values var.x originally missing var.y (Shape: X); var.y.missing: Imputed values var.y originally missing var.x (Shape: Y).","code":"plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   original.data = withNA.df, shape = TRUE )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"one-numeric-vs-one-factor","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.2 Two variables","what":"2.2.2 One numeric vs one factor","title":"Visual diagnostics for multiply imputed values","text":"can plot numeric variable versus factor using plot_1num1fac(). output function box plot overlaying points. Users required specify numeric variable var.num factor var.fac. NA.condition similar definition Section 2.2.1.","code":"plot_1num1fac(   imputation.list = imputed.data, var.num = \"BMPHEAD\", var.fac = \"HSSEX\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"two-factors","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.2 Two variables","what":"2.2.3 Two factors","title":"Visual diagnostics for multiply imputed values","text":"can generate bar plots show relationship two factors using plot_2fac().","code":"plot_2fac(   imputation.list = imputed.data, var.fac1 = \"HYD1\", var.fac2 = \"HFF1\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"one-numeric-vs-one-integer","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.2 Two variables","what":"2.2.4 One numeric vs one integer","title":"Visual diagnostics for multiply imputed values","text":"can use plot_2num() visualize relationship numeric variable integer variable. Note graphs appear differently variables var.x var.y swapped.   integer variable HSAGEIR treated factor rather numeric variable, function plot 1num1fac() can used.","code":"plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"HSAGEIR\",   original.data = withNA.df, shape = TRUE ) plot_2num(   imputation.list = imputed.data, var.x = \"HSAGEIR\", var.y = \"BMPHEAD\",   original.data = withNA.df, shape = TRUE ) plot_1num1fac(   imputation.list = imputed.data, var.num = \"BMPHEAD\", var.fac = \"HSAGEIR\",   original.data = withNA.df, shape = TRUE )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"two-integers","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.2 Two variables","what":"2.2.5 Two integers","title":"Visual diagnostics for multiply imputed values","text":"can plot two integer variables using either plot_2num() ,plot_1num1fac(), plot_2fac(). Users choose plotting functions based nature variable. example, integer variable age values 0 110, may convenient treat age numeric rather factor. , hand, integer variable just unique values (1, 2, 3), may preferable plotted factor. dataset, two variables integer type - HSHSIZER(household size) HSAGEIR(baby’s age ranging 2 11 months). Although expected relationship two, still create plot demonstration purposes.","code":"plot_2num(   imputation.list = imputed.data, var.x = \"HSHSIZER\", var.y = \"HSAGEIR\",   original.data = withNA.df, shape = TRUE ) plot_1num1fac(   imputation.list = imputed.data, var.num = \"HSHSIZER\", var.fac = \"HSAGEIR\",   original.data = withNA.df, shape = TRUE ) plot_2fac(   imputation.list = imputed.data, var.fac1 = \"HSHSIZER\", var.fac2 = \"HSAGEIR\",   original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"three-variables","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots","what":"2.3 Three variables","title":"Visual diagnostics for multiply imputed values","text":"plot multiply imputed values three variables, least one incomplete original dataset.","code":""},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"two-numeric-variables-conditional-on-one-factor","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.3 Three variables","what":"2.3.1 Two numeric variables conditional on one factor","title":"Visual diagnostics for multiply imputed values","text":"can generate scatter plot two numeric variables conditioned factor using plot_2num1fac(). variable x-axis specified var.x, whereas variable y-axis specified var.y. factor want condition con.fac.  three variables, \\(2^3\\) different types missing patterns. patterns consist possible combinations zero three variables missing. However, attempting differentiate eight types missingness plot can challenging, particularly working large datasets. Therefore, decided display following three types missing patterns (NA.condition) plot shape = TRUE. NA.condition represents following three types missing values. .observed: Observations three variables observed. appears first panel - Observed . con.fac.observed: Imputed values con.fac originally observed. (points originally missing either var.x var.y ) con.fac.missing: imputed values con.fac originally missing. (points can originally observed, missing either var.x var.y )  want treat integer variable numeric, can place either var.x var.y. example, HSAGEIR integer variable whose values range 2 11.","code":"plot_2num1fac(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   con.fac = \"HFF1\", original.data = withNA.df ) plot_2num1fac(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   con.fac = \"DMARETHN\", original.data = withNA.df, shape = TRUE ) plot_2num1fac(   imputation.list = imputed.data, var.x = \"HSAGEIR\", var.y = \"BMPRECUM\",   con.fac = \"DMARETHN\", original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"one-numeric-variable-and-one-factor-conditional-on-another-factor","dir":"Articles > Web","previous_headings":"2 Visual diagnostics plots > 2.3 Three variables","what":"2.3.2 One numeric variable and one factor conditional on another factor","title":"Visual diagnostics for multiply imputed values","text":"function plot_1num2fac() generates boxplots overlaying data points numeric variable factor, conditional another factor.","code":"plot_1num2fac(   imputation.list = imputed.data, var.fac = \"DMARETHN\", var.num = \"BMPRECUM\",   con.fac = \"HSSEX\", original.data = withNA.df )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"color-options","dir":"Articles > Web","previous_headings":"","what":"3 Color options","title":"Visual diagnostics for multiply imputed values","text":"default, observed panel gray m panels use ggplot2’s default color scheme.  color.pal argument allows users specify custom color palette vector hex codes, colorblind-friendly palette Set2 R package RColorBrewer. Note m imputed datasets, vector m+1 hex codes required extra color needed Observed panel.  Otherwise, can provide vector R’s built-color names.  useful cheat sheet R colors names created Dr Ying Wei. http://www.stat.columbia.edu/\\~tzheng/files/Rcolor.pdf","code":"plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   original.data = withNA.df, color.pal = NULL ) library(RColorBrewer) color.codes <- brewer.pal(n = 6, name = \"Set2\") color.codes #> [1] \"#66C2A5\" \"#FC8D62\" \"#8DA0CB\" \"#E78AC3\" \"#A6D854\" \"#FFD92F\"  plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   original.data = withNA.df, color.pal = color.codes ) color.names <- c(\"gray50\", \"coral2\", \"goldenrod3\", \"darkolivegreen4\", \"slateblue1\", \"plum3\")  plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   original.data = withNA.df, color.pal = color.names )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"plot-multiply-imputed-data-from-other-packages","dir":"Articles > Web","previous_headings":"","what":"4 Plot multiply imputed data from other packages","title":"Visual diagnostics for multiply imputed values","text":"can also plot multiply imputed datasets obtaining packages, mice. example using nhanes2 data mice. dataset consists just 25 rows 4 columns (age, bmi, hyp chl). 9, 8 10 missing values variables bmi, hyp, chl, respectively. Note imputed values volatile dataset small.","code":"library(mice) dim(nhanes2) #> [1] 25  4 colSums(is.na(nhanes2)) #> age bmi hyp chl  #>   0   9   8  10  imp <- mice(data = nhanes2, m = 5, printFlag = FALSE) mice.data <- complete(imp, action = \"all\") plot_hist(imputation.list = mice.data, var.name = \"bmi\", original.data = nhanes2) plot_box(imputation.list = mice.data, var.name = \"chl\", original.data = nhanes2) plot_bar(imputation.list = mice.data, var.name = \"hyp\", original.data = nhanes2) plot_2num(   imputation.list = mice.data, var.x = \"bmi\", var.y = \"chl\",   original.data = nhanes2 ) plot_1num1fac(   imputation.list = mice.data, var.num = \"chl\", var.fac = \"hyp\",   original.data = nhanes2 ) plot_2num1fac(   imputation.list = mice.data, var.x = \"chl\", var.y = \"bmi\",   con.fac = \"age\", original.data = nhanes2 ) plot_2num1fac(   imputation.list = mice.data, var.x = \"chl\", var.y = \"bmi\",   con.fac = \"hyp\", original.data = nhanes2 )"},{"path":"https://agnesdeng.github.io/mixgb/articles/web/Visual-diagnostics.html","id":"plot-against-masked-true-values","dir":"Articles > Web","previous_headings":"","what":"5 Plot against masked true values","title":"Visual diagnostics for multiply imputed values","text":"general, know true values missing data, thus can plot imputed values versus observed data. However, happen know true values (e.g., cases generated simulation), may compare imputed values. Let us generate simple dataset full.df create 30% missing values variable norm1 norm2 MCAR mechanism. impute MCAR.df dataset mixgb(). true data known, can specified argument true.data visual diagnostic functions. output extra panel called MaskedTrue, shows values originally observed intentionally made missing.","code":"N <- 1000 norm1 <- rnorm(n = N, mean = 1, sd = 1) norm2 <- rnorm(n = N, mean = 1, sd = 1) y <- norm1 + norm2 + norm1 * norm2 + rnorm(n = N, mean = 0, sd = 1) full.df <- data.frame(y = y, norm1 = norm1, norm2 = norm2) MCAR.df <- createNA(data = full.df, var.names = c(\"norm1\", \"norm2\"), p = c(0.3, 0.3))  mixgb.data <- mixgb(data = MCAR.df, m = 5, nrounds = 10) #> mixgb null start #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:37:49] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end plot_hist(   imputation.list = mixgb.data, var.name = \"norm1\",   original.data = MCAR.df, true.data = full.df ) plot_box(   imputation.list = mixgb.data, var.name = \"norm2\",   original.data = MCAR.df, true.data = full.df ) plot_2num(   imputation.list = mixgb.data, var.x = \"norm1\", var.y = \"y\",   original.data = MCAR.df, true.data = full.df )"},{"path":"https://agnesdeng.github.io/mixgb/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yongshi Deng. Author, maintainer. Thomas Lumley. Thesis advisor.","code":""},{"path":"https://agnesdeng.github.io/mixgb/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Yongshi Deng & Thomas Lumley (2023) Multiple Imputation XGBoost,       Journal Computational Graphical Statistics, DOI: 10.1080/10618600.2023.2252501","code":"@Article{,   title = {Multiple Imputation Through XGBoost},   author = {Yongshi Deng and Thomas Lumley},   journal = {Journal of Computational and Graphical Statistics},   year = {2023},   url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2023.2252501}, }"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"mixgb","dir":"","previous_headings":"","what":"Multiple Imputation Through XGBoost","title":"Multiple Imputation Through XGBoost","text":"R package mixgb provides scalable approach multiple imputation leveraging XGBoost, subsampling predictive mean matching. shown method can yield less biased estimates reflect appropriate imputation variability, achieving high computational efficiency. information, please refer paper Multiple Imputation XGBoost.","code":""},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Multiple Imputation Through XGBoost","text":"Yongshi Deng & Thomas Lumley. (2023), Multiple Imputation XGBoost, Journal Computational Graphical Statistics, DOI: 10.1080/10618600.2023.2252501. Tianqi Chen & Carlos Guestrin. (2016), XGBoost: Scalable Tree Boosting System, 22nd SIGKDD Conference Knowledge Discovery Data Mining.","code":""},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"new-updates","dir":"","previous_headings":"","what":"New updates","title":"Multiple Imputation Through XGBoost","text":"Oct 2023 Dependency Change: Starting mixgb version 1.3.1, package requires XGBoost version 2.0.0 higher. now, version available CRAN. get required version GPU support, please download XGBoost GitHub Releases. R, one can install XGBoost 2.0.0 newest version mixgb follows: prefer use CRAN version XGBoost, consider using earlier version mixgb (versions <1.3.1). Now compatible XGBoost 2.0.0! align XGBoost 2.0.0, mixgb introduces new parameter device removed parametersgpu_id predictor. Also, tree_method=\"hist\" default. mixgb(device=\"cpu\", tree_method=\"hist\",.....) mixgb(device=\"cuda\", tree_method=\"hist\",.....) Now support saving imputation models local directory JSON format. May 2023 Support logical data automatically without need convert factor type. Now mixgb(data,...) support dataset following data types: Please note variables character type need manually converted factor users imputation. January 2023 Major change default settings mixgb(). package changed using bootstrapping subsampling default setting subsample = 0.7. decision based discovery although bootstrapping generally effectively, can introduce bias certain scenarios. result, subsampling adopted default approach. May 2022 Introduce visual diagnostic functions multiply imputed data. Use S3 instead R6. Plot functions can now show masked missing data (provided). April 2022 User can adjust number iterations maxit parameter. single multiple imputation XGBoost can use predictive mean matching. Bootstrapping data obtain m imputations optional. Users can set bootstrap = FALSE disable bootstrap. Users can also set sampling-related hyperparameters XGBoost (subsample, colsample_bytree, colsample_bylevel, colsample_bynode) less 1 achieve similar effect. Add predicted mean matching type 0. Now options pmm.type NULL,0,1,2 \"auto\" (type 2 numeric/integer variables, PMM categorical variables). Add validation checks. Compatible data.table. Add function mixgb_cv() pre-tune nrounds cross-validation.","code":"# Change the file path where you saved the downloaded # XGBoost package install.packages(\"path_to_downloaded_file/xgboost_r_gpu_win64_2.0.0.tar.gz\",     repos = NULL) devtools::install_github(\"agnesdeng/mixgb\") library(mixgb) - numeric  - integer  - factor  - logical"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"under-development","dir":"","previous_headings":"","what":"Under development","title":"Multiple Imputation Through XGBoost","text":"progress: Announced Planned: Announced consideration: implement PMM type 3","code":""},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"notice","dir":"","previous_headings":"","what":"Notice","title":"Multiple Imputation Through XGBoost","text":"multithreading, users can set XGBoost nthread parameter OpenMP support. advised, OpenMP support currently disabled MacOS.","code":""},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_1-installation","dir":"","previous_headings":"","what":"1. Installation","title":"Multiple Imputation Through XGBoost","text":"can install development version mixgb GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"agnesdeng/mixgb\") # load mixgb library(mixgb)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_11-data-cleaning-before-imputation","dir":"","previous_headings":"1. Installation","what":"1.1 Data cleaning before imputation","title":"Multiple Imputation Through XGBoost","text":"highly recommended clean check data imputation. common issues: Data data frame. ID removed Missing values coded NA NaN Inf -Inf allowed Empty cells coded NA sensible values Variables “character” type converted “factor” instead Variables “factor” type least two levels function data_clean() serves purpose performing preliminary check fix evident issues. However, function resolve data quality-related problems.","code":"cleanWithNA.df <- data_clean(rawdata)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_2-impute-missing-values-with-mixgb","dir":"","previous_headings":"","what":"2. Impute missing values with mixgb","title":"Multiple Imputation Through XGBoost","text":"first load mixgb package nhanes3_newborn dataset, contains 16 variables various types (integer/numeric/factor/ordinal factor). 9 variables missing values. impute dataset, can use default settings. default number imputed datasets m = 5. Note need convert data dgCMatrix one-hot coding format. package automatically convert . Variables following types: numeric, integer, factor ordinal factor.","code":"str(nhanes3_newborn) #> tibble [2,107 × 16] (S3: tbl_df/tbl/data.frame) #>  $ HSHSIZER: int [1:2107] 4 3 5 4 4 3 5 3 3 3 ... #>  $ HSAGEIR : int [1:2107] 2 5 10 10 8 3 10 7 2 7 ... #>  $ HSSEX   : Factor w/ 2 levels \"1\",\"2\": 2 1 2 2 1 1 2 2 2 1 ... #>  $ DMARACER: Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 2 1 1 1 2 1 2 2 ... #>  $ DMAETHNR: Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 3 3 3 3 3 3 3 ... #>  $ DMARETHN: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 3 2 1 1 1 2 1 2 2 ... #>  $ BMPHEAD : num [1:2107] 39.3 45.4 43.9 45.8 44.9 42.2 45.8 NA 40.2 44.5 ... #>   ..- attr(*, \"label\")= chr \"Head circumference (cm)\" #>  $ BMPRECUM: num [1:2107] 59.5 69.2 69.8 73.8 69 61.7 74.8 NA 64.5 70.2 ... #>   ..- attr(*, \"label\")= chr \"Recumbent length (cm)\" #>  $ BMPSB1  : num [1:2107] 8.2 13 6 8 8.2 9.4 5.2 NA 7 5.9 ... #>   ..- attr(*, \"label\")= chr \"First subscapular skinfold (mm)\" #>  $ BMPSB2  : num [1:2107] 8 13 5.6 10 7.8 8.4 5.2 NA 7 5.4 ... #>   ..- attr(*, \"label\")= chr \"Second subscapular skinfold (mm)\" #>  $ BMPTR1  : num [1:2107] 9 15.6 7 16.4 9.8 9.6 5.8 NA 11 6.8 ... #>   ..- attr(*, \"label\")= chr \"First triceps skinfold (mm)\" #>  $ BMPTR2  : num [1:2107] 9.4 14 8.2 12 8.8 8.2 6.6 NA 10.9 7.6 ... #>   ..- attr(*, \"label\")= chr \"Second triceps skinfold (mm)\" #>  $ BMPWT   : num [1:2107] 6.35 9.45 7.15 10.7 9.35 7.15 8.35 NA 7.35 8.65 ... #>   ..- attr(*, \"label\")= chr \"Weight (kg)\" #>  $ DMPPIR  : num [1:2107] 3.186 1.269 0.416 2.063 1.464 ... #>   ..- attr(*, \"label\")= chr \"Poverty income ratio\" #>  $ HFF1    : Factor w/ 2 levels \"1\",\"2\": 2 2 1 1 1 2 2 1 2 1 ... #>  $ HYD1    : Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 1 3 1 1 1 1 1 1 2 1 ... colSums(is.na(nhanes3_newborn)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>        0        0        0        0        0        0      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7        0 # use mixgb with default settings imputed.data <- mixgb(data = nhanes3_newborn, m = 5)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_21-customize-imputation-settings","dir":"","previous_headings":"2. Impute missing values with mixgb","what":"2.1 Customize imputation settings","title":"Multiple Imputation Through XGBoost","text":"can also customize imputation settings: number imputed datasets m number imputation iterations maxit XGBoost hyperparameters verbose settings. xgb.params, nrounds, early_stopping_rounds, print_every_n verbose. Subsampling ratio. default, subsample = 0.7. Users can change value xgb.params argument. Predictive mean matching settings pmm.type, pmm.k pmm.link. Whether ordinal factors converted integer (imputation process may faster) ordinalAsInteger Whether use bootstrapping bootstrap Initial imputation methods different types variables initial.num, initial.int initial.fac. Whether save models imputing newdata save.models save.vars.","code":"# Use mixgb with chosen settings params <- list(max_depth = 5, subsample = 0.9, nthread = 2, tree_method = \"hist\")  imputed.data <- mixgb(data = nhanes3_newborn, m = 10, maxit = 2,     ordinalAsInteger = FALSE, bootstrap = FALSE, pmm.type = \"auto\",     pmm.k = 5, pmm.link = \"prob\", initial.num = \"normal\", initial.int = \"mode\",     initial.fac = \"mode\", save.models = FALSE, save.vars = NULL,     xgb.params = params, nrounds = 200, early_stopping_rounds = 10,     print_every_n = 10L, verbose = 0)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_22-tune-hyperparameters","dir":"","previous_headings":"2. Impute missing values with mixgb","what":"2.2 Tune hyperparameters","title":"Multiple Imputation Through XGBoost","text":"Imputation performance can affected hyperparameter settings. Although tuning large set hyperparameters may appear intimidating, often possible narrowing search space many hyperparameters correlated. package, function mixgb_cv() can used tune number boosting rounds - nrounds. default nrounds value XGBoost, users required specify value . default nrounds mixgb() 100. However, recommend using mixgb_cv() find optimal nrounds first. default, mixgb_cv() randomly choose incomplete variable response build XGBoost model variables explanatory variables using complete cases dataset. Therefore, run mixgb_cv() likely return different results. Users can also specify response covariates argument response select_features respectively. Let us just try setting nrounds = cv.results$best.nrounds mixgb() obtain 5 imputed datasets.","code":"params <- list(max_depth = 3, subsample = 0.7, nthread = 2) cv.results <- mixgb_cv(data = nhanes3_newborn, nrounds = 100,     xgb.params = params, verbose = FALSE) cv.results$response #> [1] \"BMPSB1\" cv.results$best.nrounds #> [1] 15 cv.results <- mixgb_cv(data = nhanes3_newborn, nfold = 10, nrounds = 100,     early_stopping_rounds = 1, response = \"BMPHEAD\", select_features = c(\"HSAGEIR\",         \"HSSEX\", \"DMARETHN\", \"BMPRECUM\", \"BMPSB1\", \"BMPSB2\",         \"BMPTR1\", \"BMPTR2\", \"BMPWT\"), xgb.params = params, verbose = FALSE)  cv.results$best.nrounds #> [1] 12 imputed.data <- mixgb(data = nhanes3_newborn, m = 5, nrounds = cv.results$best.nrounds)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_3-visualize-multiply-imputed-values","dir":"","previous_headings":"","what":"3. Visualize multiply imputed values","title":"Multiple Imputation Through XGBoost","text":"crucial assess plausibility imputations analysis. mixgb package provides several visual diagnostic functions using ggplot2 compare multiply imputed values versus observed data. demonstrate functions using nhanes3_newborn dataset. original data, almost missing values occurred numeric variables. seven observations missing binary factor variable HFF1. order visualize imputed values types variables, create extra missing values HSHSIZER (integer), HSAGEIR (integer), HSSEX (binary factor), DMARETHN (multiclass factor) HYD1 (Ordinal factor) missing completely random (MCAR) mechanism. impute dataset using mixgb() default settings. completion, list five imputed datasets assigned imputed.data. imputed dataset dimension original data. using function show_var(), can see multiply imputed values missing data given variable. function returns data.table m columns, represents set imputed values variable interest. Note output function includes imputed values missing entries specified variable. mixgb package provides following visual diagnostics functions: Single variable: plot_hist(), plot_box(), plot_bar() ; Two variables: plot_2num(), plot_2fac(), plot_1num1fac() ; Three variables: plot_2num1fac(), plot_1num2fac(). function returns m+1 panels enable comparison observed data m sets imputed values missing data. examples. details, please check vignette GitHub Visual diagnostics multiply imputed values.","code":"library(mixgb) colSums(is.na(nhanes3_newborn)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>        0        0        0        0        0        0      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7        0 withNA.df <- createNA(data = nhanes3_newborn, var.names = c(\"HSHSIZER\",     \"HSAGEIR\", \"HSSEX\", \"DMARETHN\", \"HYD1\"), p = 0.1) colSums(is.na(withNA.df)) #> HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM  #>      211      211      211        0        0      211      124      114  #>   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1  #>      161      169      124      167      117      192        7      211 imputed.data <- mixgb(data = withNA.df, m = 5) show_var(imputation.list = imputed.data, var.name = \"BMPHEAD\",     original.data = withNA.df) #>        m1   m2   m3   m4   m5 #>   1: 44.0 44.8 45.0 44.8 46.2 #>   2: 44.0 44.0 43.8 44.3 44.0 #>   3: 43.9 42.8 43.8 41.8 44.7 #>   4: 45.7 47.5 45.3 45.9 46.0 #>   5: 48.8 46.1 45.3 47.4 45.2 #>  ---                          #> 120: 44.7 46.9 45.3 45.0 46.2 #> 121: 44.8 46.2 46.4 45.0 45.7 #> 122: 40.8 39.9 41.6 39.9 41.9 #> 123: 44.4 42.9 43.8 44.1 42.3 #> 124: 46.3 44.6 46.1 45.1 45.1 show_var(imputation.list = imputed.data, var.name = \"HFF1\", original.data = withNA.df) #>    m1 m2 m3 m4 m5 #> 1:  2  2  2  2  2 #> 2:  1  1  1  2  1 #> 3:  1  1  1  1  1 #> 4:  2  2  2  2  2 #> 5:  1  1  1  1  1 #> 6:  1  1  1  1  1 #> 7:  2  2  2  2  2 plot_hist(imputation.list = imputed.data, var.name = \"BMPHEAD\",     original.data = withNA.df) plot_2num(imputation.list = imputed.data, var.x = \"BMPHEAD\",     var.y = \"BMPRECUM\", original.data = withNA.df) plot_2num(imputation.list = imputed.data, var.x = \"HSAGEIR\",     var.y = \"BMPHEAD\", original.data = withNA.df) plot_1num1fac(imputation.list = imputed.data, var.num = \"BMPHEAD\",     var.fac = \"HSSEX\", original.data = withNA.df)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_4-impute-new-unseen-data-using-a-saved-imputer-object","dir":"","previous_headings":"","what":"4. Impute new unseen data using a saved imputer object","title":"Multiple Imputation Through XGBoost","text":"First, let us split nhanes3_newborn dataset training data test data. can use training data generate m imputed datasets save imputation models. achieve , users need set save.models = TRUE. default, imputation models variables missing values training data saved (save.vars = NULL). However, possible unseen data may missing values variables. thorough, users can save models variables setting save.vars = colnames(train.data). Note may take significantly longer requires training saving model variable. cases users confident certain variables missing values new data, advisable specify names indices variables save.vars rather saving models variables. save.models = TRUE, mixgb() return object containing following: imputed.data: list m imputed datasets training data XGB.models: list m sets XGBoost models variables specified save.vars. params: list parameters required imputing new data using impute_new() later . can access m imputed datasets saved imputer object using $imputed.data. impute new data saved imputer object, can use impute_new() function. Users can choose whether use new data initial imputation. default, information training data used initially impute missing data new dataset (initial.newdata = FALSE). , missing values new dataset imputed using saved models imputer object. process considerably faster involve rebuilding imputation models. PMM used mixgb(), predicted values missing entries new dataset matched donors training data. Additionally, users can set number donors used PMM imputing new data. default setting pmm.k = NULL indicates setting training object used. Similarly, users can set number imputed datasets m impute_new(). Note value less equal m value specified mixgb(). value specified, function use m value saved object. Users can also specify local directory parameter save.models.folder main function mixgb(). Models save JSON format calling xgb.save() internally. Saving XGBoost models way instead using saveRDS R recommended XGBoost. can ensure imputation models can still used later release XGBoost. users specify save.models.folder, return object include following: imputed.data: list m imputed datasets training data XGB.models: list directories m sets XGBoost models variables specified save.vars. params: list parameters required imputing new data using impute_new() later . XGB.save : parameter indicates whether XGB.models saved models directories saved models. mixgb.obj contain models , users need worry saving object via saveRDS(). later use, one can load object R impute new data.","code":"library(mixgb) data(\"nhanes3_newborn\") set.seed(2022) n <- nrow(nhanes3_newborn) idx <- sample(1:n, size = round(0.7 * n), replace = FALSE) train.data <- nhanes3_newborn[idx, ] test.data <- nhanes3_newborn[-idx, ] # obtain m imputed datasets for train.data and save # imputation models mixgb.obj <- mixgb(data = train.data, m = 5, save.models = TRUE,     save.vars = NULL) train.imputed <- mixgb.obj$imputed.data # the 5th imputed dataset head(train.imputed[[5]]) #>    HSHSIZER HSAGEIR HSSEX DMARACER DMAETHNR DMARETHN BMPHEAD BMPRECUM BMPSB1 #> 1:        7       2     1        1        1        3    42.8     66.0    7.2 #> 2:        4       3     2        2        3        2    42.6     67.1    8.8 #> 3:        3       9     2        2        3        2    46.5     64.3    8.6 #> 4:        3       9     2        1        3        1    46.2     68.5   10.8 #> 5:        5       4     1        1        3        1    44.7     63.0    6.0 #> 6:        5      10     1        1        3        1    45.2     72.0    5.4 #>    BMPSB2 BMPTR1 BMPTR2 BMPWT DMPPIR HFF1 HYD1 #> 1:    6.8    8.2    8.2  7.60  1.701    2    1 #> 2:    8.8   13.3   12.2  8.70  0.102    2    1 #> 3:    8.0   10.4    9.2  8.00  0.359    1    3 #> 4:   10.0   16.6   16.0  8.98  0.561    1    3 #> 5:    5.8    9.0    9.0  7.60  2.379    2    1 #> 6:    5.4    9.2    9.4  9.00  2.173    2    2 test.imputed <- impute_new(object = mixgb.obj, newdata = test.data) test.imputed <- impute_new(object = mixgb.obj, newdata = test.data,     initial.newdata = FALSE, pmm.k = 3, m = 4) # obtain m imputed datasets for train.data and save # imputation models mixgb.obj <- mixgb(data = train.data, m = 5, save.models = TRUE,     save.models.folder = \"C:/Users/.....\") saveRDS(object = mixgb.obj, file = \"C:/Users/.../mixgbimputer.rds\") mixgb.obj <- readRDS(file = \"C:/Users/.../mixgbimputer.rds\")  set.seed(2022) n <- nrow(nhanes3) idx <- sample(1:n, size = round(0.7 * n), replace = FALSE) train.data <- nhanes3[idx, ] test.data <- nhanes3[-idx, ]  test.imputed <- impute_new(object = mixgb.obj, newdata = test.data) test.imputed"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"id_5-install-mixgb-with-gpu-support","dir":"","previous_headings":"","what":"5. Install mixgb with GPU support","title":"Multiple Imputation Through XGBoost","text":"Multiple imputation can run GPU support machines NVIDIA GPUs. Users must first install R package xgboost GPU support.","code":""},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"newest-version-xgboost--200-mixgb--131","dir":"","previous_headings":"","what":"Newest Version (XGBoost >= 2.0.0, mixgb >= 1.3.1)","title":"Multiple Imputation Through XGBoost","text":"Please download Newest version XGBoost GPU support via XGBoost GitHub Releases. users can install newest version package mixgb R. utilize GPU version mixgb(), users can simply specify device = \"cuda\" params list passed xgb.params argument function mixgb(). Note default, tree_method = \"hist\" XGBoost 2.0.0.","code":"# Change the file path where you saved the downloaded # XGBoost package install.packages(\"path_to_downloaded_file/xgboost_r_gpu_win64_2.0.0.tar.gz\",     repos = NULL) devtools::install_github(\"agnesdeng/mixgb\") library(mixgb) params <- list(device = \"cuda\", subsample = 0.7, nthread = 1,     tree_method = \"hist\")  mixgb.data <- mixgb(data = withNA.df, m = 5, xgb.params = params)"},{"path":"https://agnesdeng.github.io/mixgb/index.html","id":"old-version-xgboost--200-mixgb--131","dir":"","previous_headings":"","what":"Old Version (XGBoost < 2.0.0, mixgb < 1.3.1)","title":"Multiple Imputation Through XGBoost","text":"xgboost R package pre-built binary Linux x86_64 GPU support can downloaded release page https://github.com/dmlc/xgboost/releases/tag/v1.4.0 package can installed running following commands: users can install package mixgb R. utilize GPU version mixgb(), users can simply specify tree_method = \"gpu_hist\" params list passed xgb.params argument function mixgb(). adjustable GPU-realted arguments include gpu_id predictor. default, gpu_id = 0 predictor = \"auto\".","code":"# Install dependencies $ R -q -e \"install.packages(c('data.table', 'jsonlite'))\"  # Install XGBoost $ R CMD INSTALL ./xgboost_r_gpu_linux.tar.gz devtools::install_github(\"agnesdeng/mixgb\") library(mixgb) params <- list(max_depth = 3, subsample = 0.7, nthread = 1, tree_method = \"gpu_hist\",     gpu_id = 0, predictor = \"auto\")   mixgb.data <- mixgb(data = withNA.df, m = 5, xgb.params = params)"},{"path":"https://agnesdeng.github.io/mixgb/reference/createNA.html","id":null,"dir":"Reference","previous_headings":"","what":"Create missing values for a dataset — createNA","title":"Create missing values for a dataset — createNA","text":"function creates missing values missing complete random (MCAR) mechanism. demonstration purposes .","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/createNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create missing values for a dataset — createNA","text":"","code":"createNA(data, var.names = NULL, p = 0.3)"},{"path":"https://agnesdeng.github.io/mixgb/reference/createNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create missing values for a dataset — createNA","text":"data complete data frame. var.names names variables missing values generated. p proportion missing values data frame proportions missing values corresponding variables specified var.names.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/createNA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create missing values for a dataset — createNA","text":"data frame artificial missing values","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/createNA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create missing values for a dataset — createNA","text":"","code":"# Create 30% MCAR data across all variables in a dataset withNA.df <- createNA(data = iris, p = 0.3)  # Create 30% MCAR data in a specified variable in a dataset withNA.df <- createNA(data = iris, var.names = c(\"Sepal.Length\"), p = 0.3)  # Create MCAR data in several specified variables in a dataset withNA.df <- createNA(   data = iris,   var.names = c(\"Sepal.Length\", \"Petal.Width\", \"Species\"),   p = c(0.3, 0.2, 0.1) )"},{"path":"https://agnesdeng.github.io/mixgb/reference/data_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Data cleaning — data_clean","title":"Data cleaning — data_clean","text":"function `data_clean()` serves purpose performing preliminary check fix evident issues. However, function resolve data quality-related problems.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/data_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data cleaning — data_clean","text":"","code":"data_clean(rawdata, levels.tol = 0.2)"},{"path":"https://agnesdeng.github.io/mixgb/reference/data_clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data cleaning — data_clean","text":"rawdata data frame. levels.tol Tolerant proportion number levels number observations multiclass variable. Default: 0.2","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/data_clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data cleaning — data_clean","text":"preliminary cleaned dataset","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/data_clean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data cleaning — data_clean","text":"","code":"rawdata <- nhanes3  rawdata[4, 4] <- NaN rawdata[5, 5] <- Inf rawdata[6, 6] <- -Inf  cleandata <- data_clean(rawdata = rawdata) #> Warning: There exists at least one entry coded as NaN in the following numeric variable(s): BMPHEAD. #> It is now coverted to NA instead. #> Warning: There exists at least one entry coded as Inf or -Inf in the following variable(s): BMPRECUM;BMPWT. #> It is now coverted to NA instead."},{"path":"https://agnesdeng.github.io/mixgb/reference/default_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxiliary function for validating xgb.params — default_params","title":"Auxiliary function for validating xgb.params — default_params","text":"Auxiliary function setting default XGBoost-related hyperparameters mixgb checking xgb.params argument mixgb(). details XGBoost hyperparameters, please refer XGBoost documentation parameters. Auxiliary function setting default XGBoost-related hyperparameters mixgb checking xgb.params argument mixgb(). details XGBoost hyperparameters, please refer XGBoost documentation parameters.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/default_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auxiliary function for validating xgb.params — default_params","text":"","code":"default_params(   device = \"cpu\",   tree_method = \"hist\",   eta = 0.3,   gamma = 0,   max_depth = 3,   min_child_weight = 1,   max_delta_step = 0,   subsample = 0.7,   sampling_method = \"uniform\",   colsample_bytree = 1,   colsample_bylevel = 1,   colsample_bynode = 1,   lambda = 1,   alpha = 0,   max_leaves = 0,   max_bin = 256,   num_parallel_tree = 1,   nthread = -1 )  default_params(   device = \"cpu\",   tree_method = \"hist\",   eta = 0.3,   gamma = 0,   max_depth = 3,   min_child_weight = 1,   max_delta_step = 0,   subsample = 0.7,   sampling_method = \"uniform\",   colsample_bytree = 1,   colsample_bylevel = 1,   colsample_bynode = 1,   lambda = 1,   alpha = 0,   max_leaves = 0,   max_bin = 256,   num_parallel_tree = 1,   nthread = -1 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/default_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Auxiliary function for validating xgb.params — default_params","text":"device Can either \"cpu\" \"cuda\". ther options please refer XGBoost documentation parameters. tree_method Options: \"auto\", \"exact\", \"approx\", \"hist\". Default: \"hist\". eta Step size shrinkage. Default: 0.3. gamma Minimum loss reduction required make partition leaf node tree. Default: 0 max_depth Maximum depth tree. Default: 3. min_child_weight Minimum sum instance weight needed child. Default: 1. max_delta_step Maximum delta step. Default: 0. subsample Subsampling ratio data. Default: 0.7. sampling_method method used sample data. Default: \"uniform\". colsample_bytree Subsampling ratio columns constructing tree. Default: 1. colsample_bylevel Subsampling ratio columns level. Default: 1. colsample_bynode Subsampling ratio columns node. Default: 1. lambda L2 regularization term weights. Default: 1. alpha L1 regularization term weights. Default: 0. max_leaves Maximum number nodes added (used tree_method = \"exact\". Default: 0. max_bin Maximum number discrete bins bucket continuous features (used tree_method either hist, approx gpu_hist. Default: 256. num_parallel_tree number parallel trees used boosted random forests. Default: 1. nthread number CPU threads used. Default: -1 (available threads).","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/default_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Auxiliary function for validating xgb.params — default_params","text":"list hyperparameters. list hyperparameters.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/default_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Auxiliary function for validating xgb.params — default_params","text":"","code":"default_params() #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.7 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] -1 #>   xgb.params <- list(subsample = 0.9, nthread = 2) default_params(subsample = xgb.params$subsample, nthread = xgb.params$nthread) #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.9 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] 2 #>   xgb.params <- do.call(\"default_params\", xgb.params) xgb.params #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.9 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] 2 #>  default_params() #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.7 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] -1 #>   xgb.params <- list(subsample = 0.9, nthread = 2) default_params(subsample = xgb.params$subsample, nthread = xgb.params$nthread) #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.9 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] 2 #>   xgb.params <- do.call(\"default_params\", xgb.params) xgb.params #> $device #> [1] \"cpu\" #>  #> $tree_method #> [1] \"hist\" #>  #> $eta #> [1] 0.3 #>  #> $gamma #> [1] 0 #>  #> $max_depth #> [1] 3 #>  #> $min_child_weight #> [1] 1 #>  #> $subsample #> [1] 0.9 #>  #> $sampling_method #> [1] \"uniform\" #>  #> $colsample_bytree #> [1] 1 #>  #> $colsample_bylevel #> [1] 1 #>  #> $colsample_bynode #> [1] 1 #>  #> $lambda #> [1] 1 #>  #> $alpha #> [1] 0 #>  #> $max_leaves #> [1] 0 #>  #> $max_bin #> [1] 256 #>  #> $num_parallel_tree #> [1] 1 #>  #> $nthread #> [1] 2 #>"},{"path":"https://agnesdeng.github.io/mixgb/reference/impute_new.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute new data with a saved mixgb imputer object — impute_new","title":"Impute new data with a saved mixgb imputer object — impute_new","text":"Impute new data saved mixgb imputer object","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/impute_new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute new data with a saved mixgb imputer object — impute_new","text":"","code":"impute_new(   object,   newdata,   initial.newdata = FALSE,   pmm.k = NULL,   m = NULL,   verbose = FALSE )"},{"path":"https://agnesdeng.github.io/mixgb/reference/impute_new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute new data with a saved mixgb imputer object — impute_new","text":"object saved imputer object created mixgb(..., save.models = TRUE) newdata data.frame data.table. New data missing values. initial.newdata Whether use information new data initially impute missing values new data. default, set FALSE, original data passed mixgb() used initial imputation. pmm.k number donors predictive mean matching. NULL (default), pmm.k value saved imputer object used. m number imputed datasets. NULL (default), m value saved imputer object used. verbose Verbose setting mixgb. TRUE, print progress imputation. Default: FALSE.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/impute_new.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute new data with a saved mixgb imputer object — impute_new","text":"list m imputed datasets new data.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/impute_new.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute new data with a saved mixgb imputer object — impute_new","text":"","code":"set.seed(2022) n <- nrow(nhanes3) idx <- sample(1:n, size = round(0.7 * n), replace = FALSE) train.data <- nhanes3[idx, ] test.data <- nhanes3[-idx, ]  params <- list(max_depth = 3, subsample = 0.7, nthread = 2) mixgb.obj <- mixgb(data = train.data, m = 2, xgb.params = params, nrounds = 10, save.models = TRUE) #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>   # obtain m imputed datasets for train.data train.imputed <- mixgb.obj$imputed.data train.imputed #> [[1]] #>      HSAGEIR HSSEX DMARETHN BMPHEAD BMPRECUM BMPWT #>   1:      10     2        3    45.7     70.2  8.15 #>   2:       3     1        4    42.0     63.5  7.50 #>   3:       3     2        1    43.2     63.1  6.75 #>   4:       9     2        2    44.4     73.5  8.30 #>   5:       9     1        1    45.3     73.8  9.10 #>  ---                                               #> 346:       4     1        2    44.8     66.7  8.60 #> 347:       2     1        1    41.4     60.0  6.75 #> 348:       5     2        2    40.4     63.2  7.35 #> 349:       5     1        2    44.0     69.1  8.75 #> 350:      11     1        3    47.1     77.8 10.35 #>  #> [[2]] #>      HSAGEIR HSSEX DMARETHN BMPHEAD BMPRECUM BMPWT #>   1:      10     2        3    45.7     70.2  8.15 #>   2:       3     1        4    42.0     63.5  7.50 #>   3:       3     2        1    43.2     63.1  6.75 #>   4:       9     2        2    44.4     73.5  8.30 #>   5:       9     1        1    45.3     73.8  9.10 #>  ---                                               #> 346:       4     1        2    44.8     66.7  8.60 #> 347:       2     1        1    41.4     60.0  6.75 #> 348:       5     2        2    40.4     63.2  7.35 #> 349:       5     1        2    44.0     69.1  8.75 #> 350:      11     1        3    47.1     77.8 10.35 #>   # use the saved imputer to impute new data test.imputed <- impute_new(object = mixgb.obj, newdata = test.data) test.imputed #> [[1]] #>      HSAGEIR HSSEX DMARETHN BMPHEAD BMPRECUM BMPWT #>   1:       3     2        2    42.6     67.1  8.70 #>   2:       8     1        2    47.4     78.2 10.75 #>   3:       9     1        2    45.1     73.0  8.40 #>   4:       9     1        1    44.3     73.3  8.70 #>   5:       3     1        1    43.4     65.1  7.35 #>  ---                                               #> 146:       2     1        3    35.7     49.5  3.80 #> 147:       7     1        1    45.5     70.7 10.40 #> 148:       6     2        4    46.7     66.9  8.10 #> 149:      11     2        4    46.4     73.5  9.15 #> 150:       9     2        2    45.9     71.0  8.55 #>  #> [[2]] #>      HSAGEIR HSSEX DMARETHN BMPHEAD BMPRECUM BMPWT #>   1:       3     2        2    42.6     67.1  8.70 #>   2:       8     1        2    47.4     78.2 10.75 #>   3:       9     1        2    45.1     73.0  8.40 #>   4:       9     1        1    44.3     73.3  8.70 #>   5:       3     1        1    43.4     65.1  7.35 #>  ---                                               #> 146:       2     1        3    35.7     49.5  3.80 #> 147:       7     1        1    45.5     70.7 10.40 #> 148:       6     2        4    46.7     66.9  8.10 #> 149:      11     2        4    46.4     73.5  9.15 #> 150:       9     2        2    45.9     71.0  8.55 #>"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb-package.html","id":null,"dir":"Reference","previous_headings":"","what":"mixgb: Multiple Imputation Through XGBoost — mixgb-package","title":"mixgb: Multiple Imputation Through XGBoost — mixgb-package","text":"Multiple imputation using 'XGBoost', subsampling, predictive mean matching described Deng Lumley (2023) <arXiv:2106.01574>. method utilizes capabilities XGBoost, highly efficient implementation gradient boosted trees, capture interactions non-linear relations automatically. Moreover, integrated subsampling predictive mean matching minimize bias reflect appropriate imputation variability. package supports various types variables offers flexible settings subsampling predictive mean matching. Additionally, includes diagnostic tools evaluating quality imputed values.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"mixgb: Multiple Imputation Through XGBoost — mixgb-package","text":"Deng, Y., & Lumley, T. (2023), Multiple Imputation XGBoost, Journal Computational Graphical Statistics, DOI: 10.1080/10618600.2023.2252501. Chen, T., & Guestrin, C. (2016), XGBoost: Scalable Tree Boosting System, Proceedings 22nd ACM SIGKDD International Conference Knowledge Discovery Data Mining (pp. 785-794). van Buuren, S., Brand, J. P., Groothuis-Oudshoorn, C. G., & Rubin, D. B. (2006), Fully Conditional Specification Multivariate Imputation, Journal Statistical Computation Simulation, 76(12), 1049-1064. van Buuren, S. (2018), Flexible Imputation Missing Data, Second Edition, Chapman & Hall/CRC. Boca Raton, FL. Rubin, D. B. (1986), Statistical Matching Using File Concatenation Adjusted Weights Multiple Imputations, Journal Business & Economic Statistics, 4(1), 87. Little, R. J. (1988), Missing-data Adjustments Large Surveys, Journal Business & Economic Statistics, 6(3), 287.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple imputation through XGBoost — mixgb","title":"Multiple imputation through XGBoost — mixgb","text":"function used generate multiply imputed datasets using XGBoost, subsampling predictive mean matching (PMM).","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple imputation through XGBoost — mixgb","text":"","code":"mixgb(   data,   m = 5,   maxit = 1,   ordinalAsInteger = FALSE,   bootstrap = FALSE,   pmm.type = \"auto\",   pmm.k = 5,   pmm.link = \"prob\",   initial.num = \"normal\",   initial.int = \"mode\",   initial.fac = \"mode\",   save.models = FALSE,   save.vars = NULL,   save.models.folder = NULL,   verbose = F,   xgb.params = list(),   nrounds = 100,   early_stopping_rounds = 10,   print_every_n = 10L,   xgboost_verbose = 0,   ... )"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple imputation through XGBoost — mixgb","text":"data data.frame data.table missing values m number imputed datasets. Default: 5 maxit number imputation iterations. Default: 1 ordinalAsInteger Whether convert ordinal factors integers. default, ordinalAsInteger = FALSE. Setting ordinalAsInteger = TRUE may speed imputation process large datasets. bootstrap Whether use bootstrapping multiple imputation. default, bootstrap = FALSE. Setting bootstrap = TRUE can improve imputation variability sampling-related hyperparameters XGBoost set 1. pmm.type type predictive mean matching (PMM). Possible values: NULL: Imputations without PMM; 0: Imputations PMM type 0; 1: Imputations PMM type 1; 2: Imputations PMM type 2; \"auto\" (Default): Imputations PMM type 2 numeric/integer variables; imputations without PMM categorical variables. pmm.k number donors predictive mean matching. Default: 5 pmm.link link predictive mean matching binary variables \"prob\" (Default): use probabilities; \"logit\": use logit values. initial.num Initial imputation method numeric type data: \"normal\" (Default); \"mean\"; \"median\"; \"mode\"; \"sample\". initial.int Initial imputation method integer type data: \"mode\" (Default); \"sample\". initial.fac Initial imputation method factor type data: \"mode\" (Default); \"sample\". save.models Whether save imputation models imputing new data later . Default: FALSE save.vars purpose imputing new data, imputation models response variables specified save.vars saved. values save.vars can vector names indices. default, imputation models variables missing values original data saved (save.vars = NULL). save imputation models variables, users can specify save.vars = colnames(data). save.models.folder Users can specify folder directory save imputation models. Models saved JSON format internally calling xgb.save(), recommended XGBoost. verbose Verbose setting mixgb. TRUE, print progress imputation. Default: FALSE. xgb.params list XGBoost parameters. details, please check XGBoost documentation parameters. nrounds maximum number boosting iterations XGBoost. Default: 100 early_stopping_rounds integer value k. XGBoost training stop validation performance improved k rounds. Default: 10. print_every_n Print XGBoost evaluation information every nth iteration xgboost_verbose > 0. xgboost_verbose Verbose setting XGBoost training: 0 (silent), 1 (print information) 2 (print additional information). Default: 0 ... Extra arguments passed XGBoost","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple imputation through XGBoost — mixgb","text":"save.models = FALSE, function return list m imputed datasets. save.models = TRUE, return object imputed datasets, saved models parameters.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple imputation through XGBoost — mixgb","text":"","code":"# obtain m multiply datasets without saving models params <- list(max_depth = 3, subsample = 0.7, nthread = 2) mixgb.data <- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10) #> mixgb null start #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:29] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # obtain m multiply imputed datasets and save models for imputing new data later on mixgb.obj <- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10, save.models = TRUE) #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb0.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple imputation through XGBoost — mixgb0","title":"Multiple imputation through XGBoost — mixgb0","text":"function used generate multiply imputed datasets using XGBoost, subsampling predictive mean matching (PMM).","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple imputation through XGBoost — mixgb0","text":"","code":"mixgb0(   data,   m = 5,   maxit = 1,   ordinalAsInteger = FALSE,   bootstrap = FALSE,   pmm.type = \"auto\",   pmm.k = 5,   pmm.link = \"prob\",   initial.num = \"normal\",   initial.int = \"mode\",   initial.fac = \"mode\",   save.models = FALSE,   save.vars = NULL,   save.models.folder = NULL,   verbose = F,   xgb.params = list(),   nrounds = 100,   early_stopping_rounds = 10,   print_every_n = 10L,   xgboost_verbose = 0,   ... )"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple imputation through XGBoost — mixgb0","text":"data data.frame data.table missing values m number imputed datasets. Default: 5 maxit number imputation iterations. Default: 1 ordinalAsInteger Whether convert ordinal factors integers. default, ordinalAsInteger = FALSE. Setting ordinalAsInteger = TRUE may speed imputation process large datasets. bootstrap Whether use bootstrapping multiple imputation. default, bootstrap = FALSE. Setting bootstrap = TRUE can improve imputation variability sampling-related hyperparameters XGBoost set 1. pmm.type type predictive mean matching (PMM). Possible values: NULL: Imputations without PMM; 0: Imputations PMM type 0; 1: Imputations PMM type 1; 2: Imputations PMM type 2; \"auto\" (Default): Imputations PMM type 2 numeric/integer variables; imputations without PMM categorical variables. pmm.k number donors predictive mean matching. Default: 5 pmm.link link predictive mean matching binary variables \"prob\" (Default): use probabilities; \"logit\": use logit values. initial.num Initial imputation method numeric type data: \"normal\" (Default); \"mean\"; \"median\"; \"mode\"; \"sample\". initial.int Initial imputation method integer type data: \"mode\" (Default); \"sample\". initial.fac Initial imputation method factor type data: \"mode\" (Default); \"sample\". save.models Whether save imputation models imputing new data later . Default: FALSE save.vars purpose imputing new data, imputation models response variables specified save.vars saved. values save.vars can vector names indices. default, imputation models variables missing values original data saved (save.vars = NULL). save imputation models variables, users can specify save.vars = colnames(data). save.models.folder Users can specify folder directory save imputation models. Models saved JSON format internally calling xgb.save(), recommended XGBoost. verbose Verbose setting mixgb. TRUE, print progress imputation. Default: FALSE. xgb.params list XGBoost parameters. details, please check XGBoost documentation parameters. nrounds maximum number boosting iterations XGBoost. Default: 100 early_stopping_rounds integer value k. XGBoost training stop validation performance improved k rounds. Default: 10. print_every_n Print XGBoost evaluation information every nth iteration xgboost_verbose > 0. xgboost_verbose Verbose setting XGBoost training: 0 (silent), 1 (print information) 2 (print additional information). Default: 0 ... Extra arguments passed XGBoost","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple imputation through XGBoost — mixgb0","text":"save.models = FALSE, function return list m imputed datasets. save.models = TRUE, return object imputed datasets, saved models parameters.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple imputation through XGBoost — mixgb0","text":"","code":"# obtain m multiply datasets without saving models params <- list(max_depth = 3, subsample = 0.7, nthread = 2) mixgb.data <- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10) #> mixgb null start #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # obtain m multiply imputed datasets and save models for imputing new data later on mixgb.obj <- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10, save.models = TRUE) #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Use cross-validation to find the optimal nrounds — mixgb_cv","title":"Use cross-validation to find the optimal nrounds — mixgb_cv","text":"Use cross-validation find optimal nrounds Mixgb imputer. Note method relies complete cases dataset obtain optimal nrounds.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use cross-validation to find the optimal nrounds — mixgb_cv","text":"","code":"mixgb_cv(   data,   nfold = 5,   nrounds = 100,   early_stopping_rounds = 10,   response = NULL,   select_features = NULL,   xgb.params = list(),   stringsAsFactors = FALSE,   verbose = TRUE,   ... )"},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use cross-validation to find the optimal nrounds — mixgb_cv","text":"data data.frame data.table missing values. nfold number subsamples randomly partitioned equal size. Default: 5 nrounds max number iterations XGBoost training. Default: 100 early_stopping_rounds integer value k. Training stop validation performance improved k rounds. response name column index response variable. Default: NULL (Randomly select incomplete variable). select_features names indices selected features. Default: NULL (Select variables dataset). xgb.params list XGBoost parameters. details, please check XGBoost documentation parameters. stringsAsFactors logical value indicating whether character vectors dataset converted factors. verbose logical value. Whether print cross-validation results process. ... Extra arguments passed XGBoost.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use cross-validation to find the optimal nrounds — mixgb_cv","text":"list optimal nrounds, evaluation.log chosen response.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/mixgb_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use cross-validation to find the optimal nrounds — mixgb_cv","text":"","code":"params <- list(max_depth = 3, subsample = 0.7, nthread = 2) cv.results <- mixgb_cv(data = nhanes3, xgb.params = params) #> [1]\ttrain-rmse:30.545517+0.035918\ttest-rmse:30.544277+0.271264  #> Multiple eval metrics are present. Will use test_rmse for early stopping. #> Will train until test_rmse hasn't improved in 10 rounds. #>  #> [2]\ttrain-rmse:21.483645+0.025808\ttest-rmse:21.480103+0.231940  #> [3]\ttrain-rmse:15.116835+0.020760\ttest-rmse:15.107923+0.225282  #> [4]\ttrain-rmse:10.671798+0.018323\ttest-rmse:10.669365+0.221007  #> [5]\ttrain-rmse:7.570427+0.024380\ttest-rmse:7.566586+0.213362  #> [6]\ttrain-rmse:5.393886+0.008696\ttest-rmse:5.401710+0.216204  #> [7]\ttrain-rmse:3.889877+0.016558\ttest-rmse:3.905897+0.203964  #> [8]\ttrain-rmse:2.859279+0.020708\ttest-rmse:2.908546+0.196896  #> [9]\ttrain-rmse:2.174245+0.019184\ttest-rmse:2.246636+0.199209  #> [10]\ttrain-rmse:1.728843+0.015718\ttest-rmse:1.832092+0.206172  #> [11]\ttrain-rmse:1.454143+0.016778\ttest-rmse:1.597323+0.197925  #> [12]\ttrain-rmse:1.283570+0.017158\ttest-rmse:1.453027+0.199082  #> [13]\ttrain-rmse:1.185837+0.024135\ttest-rmse:1.387727+0.187128  #> [14]\ttrain-rmse:1.126033+0.024964\ttest-rmse:1.341096+0.183840  #> [15]\ttrain-rmse:1.089111+0.032074\ttest-rmse:1.324841+0.179840  #> [16]\ttrain-rmse:1.062118+0.030643\ttest-rmse:1.308819+0.178305  #> [17]\ttrain-rmse:1.042065+0.028825\ttest-rmse:1.308179+0.175313  #> [18]\ttrain-rmse:1.027044+0.028619\ttest-rmse:1.313738+0.175036  #> [19]\ttrain-rmse:1.012320+0.028990\ttest-rmse:1.310390+0.170543  #> [20]\ttrain-rmse:1.003871+0.028776\ttest-rmse:1.315807+0.169610  #> [21]\ttrain-rmse:0.992036+0.031028\ttest-rmse:1.319184+0.166053  #> [22]\ttrain-rmse:0.984058+0.028442\ttest-rmse:1.318963+0.165403  #> [23]\ttrain-rmse:0.973277+0.028034\ttest-rmse:1.316435+0.166257  #> [24]\ttrain-rmse:0.963377+0.028617\ttest-rmse:1.320910+0.165242  #> [25]\ttrain-rmse:0.954724+0.029640\ttest-rmse:1.317917+0.167060  #> [26]\ttrain-rmse:0.945546+0.031059\ttest-rmse:1.319450+0.164086  #> [27]\ttrain-rmse:0.933054+0.028400\ttest-rmse:1.322332+0.166577  #> Stopping. Best iteration: #> [17]\ttrain-rmse:1.042065+0.028825\ttest-rmse:1.308179+0.175313 #>  cv.results$best.nrounds #> [1] 17  imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = cv.results$best.nrounds) #> mixgb null start #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:30] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end"},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3.html","id":null,"dir":"Reference","previous_headings":"","what":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","title":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","text":"dataset small subset nhanes3_newborn. demonstration purposes . information NHANES III data can found https://wwwn.cdc.gov/Nchs/Data/Nhanes3/7a/doc/mimodels.pdf","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","text":"","code":"data(nhanes3)"},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","text":"data frame 500 rows 6 variables. Three variables missing values. HSAGEIR Age interview (screener) - qty (months). integer variable 2 11. HSSEX Sex. factor variable levels 1 (Male) 2 (Female). DMARETHN Race-ethnicity. factor variable levels 1 (Non-Hispanic white), 2 (Non-Hispanic black), 3 (Mexican-American) 4 (). BMPHEAD Head circumference (cm). Numeric. BMPRECUM Recumbent length (cm). Numeric. BMPWT Weight (kg). Numeric.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","text":"https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A small subset of the NHANES III (1988-1994) newborn data — nhanes3","text":"U.S. Department Health Human Services (DHHS).  National Center Health Statistics.  Third National Health Nutrition Examination Survey (NHANES III, 1988-1994): Multiply Imputed Data Set. CD-ROM, Series 11, . 7A. Hyattsville, MD: Centers Disease Control Prevention, 2001. Includes access software: Adobe Systems, Inc. Acrobat Reader version 4.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3_newborn.html","id":null,"dir":"Reference","previous_headings":"","what":"NHANES III (1988-1994) newborn data — nhanes3_newborn","title":"NHANES III (1988-1994) newborn data — nhanes3_newborn","text":"dataset extracted NHANES III (1988-1994) age class Newborn (1 year). Please note example dataset contains selected variables demonstration purposes .","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3_newborn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NHANES III (1988-1994) newborn data — nhanes3_newborn","text":"","code":"data(nhanes3_newborn)"},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3_newborn.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NHANES III (1988-1994) newborn data — nhanes3_newborn","text":"data frame 2107 rows 16 variables. Nine variables missing values. HSHSIZER Household size. integer variable 1 10. HSAGEIR Age interview (screener) - qty (months). integer variable 2 11. HSSEX Sex. factor variable levels 1 (Male) 2 (Female). DMARACER Race. factor variable levels 1 (White), 2 (Black) 3 (). DMAETHNR Ethnicity. factor variable levels 1 (Mexican-American), 2 (Hispanic) 3 (Hispanic). DMARETHN Race-ethnicity. factor variable levels 1 (Non-Hispanic white), 2 (Non-Hispanic black), 3 (Mexican-American) 4 (). BMPHEAD Head circumference (cm). Numeric. BMPRECUM Recumbent length (cm). Numeric. BMPSB1 First subscapular skinfold (mm). Numeric. BMPSB2 Second subscapular skinfold (mm). Numeric. BMPTR1 First triceps skinfold (mm). Numeric. BMPTR2 Second triceps skinfold (mm). Numeric. BMPWT Weight (kg). Numeric. DMPPIR Poverty income ratio. Numeric. HFF1 anyone lives smoke cigarettes home? factor variable levels 1 (Yes) 2 (). HYD1 health subject person general? ordinal factor levels 1 (Excellent), 2 (good), 3 (Good), 4 (Fair) 5 (Poor).","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3_newborn.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NHANES III (1988-1994) newborn data — nhanes3_newborn","text":"https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/nhanes3_newborn.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"NHANES III (1988-1994) newborn data — nhanes3_newborn","text":"U.S. Department Health Human Services (DHHS).  National Center Health Statistics.  Third National Health Nutrition Examination Survey (NHANES III, 1988-1994): Multiply Imputed Data Set. CD-ROM, Series 11, . 7A. Hyattsville, MD: Centers Disease Control Prevention, 2001. Includes access software: Adobe Systems, Inc. Acrobat Reader version 4.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num1fac.html","id":null,"dir":"Reference","previous_headings":"","what":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","title":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","text":"Plot observed values versus m sets imputed values one numeric variable vs one factor (integer) variable using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num1fac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","text":"","code":"plot_1num1fac(   imputation.list,   var.num,   var.fac,   original.data,   true.data = NULL,   color.pal = NULL,   shape = FALSE )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num1fac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","text":"imputation.list list m imputed datasets returned mixgb imputer var.num numeric variable var.fac factor variable original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.) shape Whether plot shapes different types missing values. default, set FALSE speed plotting. recommend using `shape = TRUE` small datasets.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num1fac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","text":"Box plot jittered data points numeric/integer variable; Bar plot categorical variable.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num1fac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box plots with points for one numeric variable vs one factor (or integer) variable. — plot_1num1fac","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:31] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variables \"BMPHEAD\" versus \"HSSEX\" plot_1num1fac(   imputation.list = imputed.data, var.num = \"BMPHEAD\", var.fac = \"HSSEX\",   original.data = nhanes3 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num2fac.html","id":null,"dir":"Reference","previous_headings":"","what":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","title":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","text":"Plot observed values versus m sets imputed values one specified numeric variable two factors using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num2fac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","text":"","code":"plot_1num2fac(   imputation.list,   var.fac,   var.num,   con.fac,   original.data,   true.data = NULL,   color.pal = NULL,   shape = FALSE )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num2fac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","text":"imputation.list list m imputed datasets returned mixgb imputer var.fac factor variable x-axis var.num numeric variable y-axis con.fac name factor condition original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.) shape Whether plot shapes different types missing values. default, set FALSE speed plotting. recommend using `shape = TRUE` small datasets.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num2fac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","text":"Boxplots overlaying data points","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_1num2fac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box plots with overlaying data points for a numeric variable vs a factor condition on another factor — plot_1num2fac","text":"","code":"# create some extra missing values in factor variables \"HSSEX\" and \"DMARETHN\" nhanes3_NA <- createNA(nhanes3, var.names = c(\"HSSEX\", \"DMARETHN\"), p = 0.1)  # obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3_NA, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:32] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:33] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variables \"BMPRECUM\" versus \"HSSEX\" conditional on \"DMARETHN\" plot_1num2fac(   imputation.list = imputed.data, var.fac = \"HSSEX\", var.num = \"BMPRECUM\",   con.fac = \"DMARETHN\", original.data = nhanes3_NA )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2fac.html","id":null,"dir":"Reference","previous_headings":"","what":"Bar plots for two imputed factor variables — plot_2fac","title":"Bar plots for two imputed factor variables — plot_2fac","text":"Plot observed values versus m sets imputed values two specified numeric variables using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2fac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bar plots for two imputed factor variables — plot_2fac","text":"","code":"plot_2fac(   imputation.list,   var.fac1,   var.fac2,   original.data,   true.data = NULL,   color.pal = NULL )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2fac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bar plots for two imputed factor variables — plot_2fac","text":"imputation.list list m imputed datasets returned mixgb imputer var.fac1 factor variable var.fac2 factor variable original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.)","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2fac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bar plots for two imputed factor variables — plot_2fac","text":"Scatter plots two numeric/integer variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2fac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bar plots for two imputed factor variables — plot_2fac","text":"","code":"# create some extra missing values in factor variables \"HSSEX\" and \"DMARETHN\" nhanes3_NA <- createNA(nhanes3, var.names = c(\"HSSEX\", \"DMARETHN\"), p = 0.1)  # obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3_NA, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:34] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:35] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end   # plot the multiply imputed values for variables \"HSSEX\" versus \"DMARETHN\" plot_2fac(   imputation.list = imputed.data, var.fac1 = \"DMARETHN\", var.fac2 = \"HSSEX\",   original.data = nhanes3_NA )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter plots for two imputed numeric variables — plot_2num","title":"Scatter plots for two imputed numeric variables — plot_2num","text":"Plot observed values versus m sets imputed values two specified numeric variables using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter plots for two imputed numeric variables — plot_2num","text":"","code":"plot_2num(   imputation.list,   var.x,   var.y,   original.data,   true.data = NULL,   color.pal = NULL,   shape = FALSE )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter plots for two imputed numeric variables — plot_2num","text":"imputation.list list m imputed datasets returned mixgb imputer var.x numeric variable x-axis var.y numeric variable y-axis original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.) shape Whether plot shapes different types missing values. default, set FALSE speed plotting. recommend using `shape = TRUE` small datasets.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter plots for two imputed numeric variables — plot_2num","text":"Scatter plots two numeric/integer variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter plots for two imputed numeric variables — plot_2num","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variables \"BMPRECUM\" versus \"BMPHEAD\" plot_2num(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   original.data = nhanes3 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num1fac.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","title":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","text":"Plot observed values versus m sets imputed values two specified numeric variables factor using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num1fac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","text":"","code":"plot_2num1fac(   imputation.list,   var.x,   var.y,   con.fac,   original.data,   true.data = NULL,   color.pal = NULL,   shape = FALSE )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num1fac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","text":"imputation.list list m imputed datasets returned mixgb imputer var.x numeric variable x-axis var.y numeric variable y-axis con.fac name factor condition original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.) shape Whether plot shapes different types missing values. default, set FALSE speed plotting. recommend using `shape = TRUE` small datasets.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num1fac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","text":"Scatter plots","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_2num1fac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter plots for two imputed numeric variables conditional on a factor — plot_2num1fac","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:36] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:37] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variables \"BMPRECUM\" versus \"BMPHEAD\" conditional on \"HSSEX\" plot_2num1fac(   imputation.list = imputed.data, var.x = \"BMPHEAD\", var.y = \"BMPRECUM\",   con.fac = \"HSSEX\", original.data = nhanes3 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_bar.html","id":null,"dir":"Reference","previous_headings":"","what":"Bar plots for multiply imputed values for a single factor variable — plot_bar","title":"Bar plots for multiply imputed values for a single factor variable — plot_bar","text":"Plot bar plots observed values versus m sets imputed values specified factor variable using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_bar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bar plots for multiply imputed values for a single factor variable — plot_bar","text":"","code":"plot_bar(   imputation.list,   var.name,   original.data,   true.data = NULL,   color.pal = NULL )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_bar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bar plots for multiply imputed values for a single factor variable — plot_bar","text":"imputation.list list m imputed datasets returned mixgb imputer var.name name factor variable interest original.data original data missing data true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.)","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_bar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bar plots for multiply imputed values for a single factor variable — plot_bar","text":"Bar plots factor variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_bar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bar plots for multiply imputed values for a single factor variable — plot_bar","text":"","code":"# create some extra missing values in a factor variable \"HSSEX\" (originally fully observed) nhanes3_NA <- createNA(nhanes3, var.names = \"HSSEX\", p = 0.1)  # obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3_NA, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:38] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variable \"HSSEX\" plot_bar(   imputation.list = imputed.data, var.name = \"HSSEX\",   original.data = nhanes3_NA )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_box.html","id":null,"dir":"Reference","previous_headings":"","what":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","title":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","text":"Plot boxplots data points observed values versus m sets imputed values specified numeric variable using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_box.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","text":"","code":"plot_box(   imputation.list,   var.name,   original.data,   true.data = NULL,   color.pal = NULL )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_box.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","text":"imputation.list list m imputed datasets. var.name name numeric variable interest. original.data original data missing values. true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.)","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_box.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","text":"Boxplots data points numeric variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_box.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boxplots with data points for multiply imputed values for a single numeric variable — plot_box","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variable \"BMPHEAD\" plot_box(   imputation.list = imputed.data, var.name = \"BMPHEAD\",   original.data = nhanes3 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","title":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","text":"Plot histograms density curves observed values versus m sets imputed values specified numeric variable using ggplot2.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","text":"","code":"plot_hist(   imputation.list,   var.name,   original.data,   true.data = NULL,   color.pal = NULL )"},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","text":"imputation.list list m imputed datasets returned mixgb imputer, package. var.name name numeric variable interest. original.data original data missing values. true.data true data without missing values. generally unknown practice. true data known (e.g., cases generated simulation), can specified argument. output extra panel called MaskedTrue, shows values originally observed intentionally made missing. color.pal vector hex color codes observed m sets imputed values panels. vector length m+1. Default: NULL (use \"gray40\" observed panel, use ggplot2 default colors panels.)","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","text":"Histogram density plots","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/plot_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histogram with density plots for multiply imputed values for a single numeric variable — plot_hist","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 0.8, nthread = 2) imputed.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 30) #> mixgb null start #> [21:36:39] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:40] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  # plot the multiply imputed values for variable \"BMPHEAD\" plot_hist(   imputation.list = imputed.data, var.name = \"BMPHEAD\",   original.data = nhanes3 )"},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.html","id":null,"dir":"Reference","previous_headings":"","what":"PMM for numeric or binary variable — pmm","title":"PMM for numeric or binary variable — pmm","text":"PMM numeric binary variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PMM for numeric or binary variable — pmm","text":"","code":"pmm(yhatobs, yhatmis, yobs, k)"},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PMM for numeric or binary variable — pmm","text":"yhatobs predicted values observed entries variable yhatmis predicted values missing entries variable yobs actual observed values observed entries variable k number donors.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PMM for numeric or binary variable — pmm","text":"matched observed values missing entries","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.multiclass.html","id":null,"dir":"Reference","previous_headings":"","what":"PMM for multiclass variable — pmm.multiclass","title":"PMM for multiclass variable — pmm.multiclass","text":"PMM multiclass variable","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.multiclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PMM for multiclass variable — pmm.multiclass","text":"","code":"pmm.multiclass(yhatobs, yhatmis, yobs, k)"},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.multiclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PMM for multiclass variable — pmm.multiclass","text":"yhatobs predicted values observed entries variable yhatmis predicted values missing entries variable yobs actual observed values observed entries variable k number donors.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/pmm.multiclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PMM for multiclass variable — pmm.multiclass","text":"matched observed values missing entries","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/show_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Show multiply imputed values for a single variable — show_var","title":"Show multiply imputed values for a single variable — show_var","text":"Show m sets imputed values specified variable.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/show_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show multiply imputed values for a single variable — show_var","text":"","code":"show_var(imputation.list, var.name, original.data, true.values = NULL)"},{"path":"https://agnesdeng.github.io/mixgb/reference/show_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show multiply imputed values for a single variable — show_var","text":"imputation.list list m imputed datasets returned mixgb imputer. var.name name variable interest. original.data original data missing data. true.values vector true values (known) missing values. general, unknown (true.values = NULL).","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/show_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show multiply imputed values for a single variable — show_var","text":"data.table m columns, represents set imputed values variable interest. true.values provided, additional column display true values missing values.","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/show_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show multiply imputed values for a single variable — show_var","text":"","code":"# obtain m multiply datasets params <- list(max_depth = 3, subsample = 1, nthread = 2) mixgb.data <- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = 20) #> mixgb null start #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end #> mixgb null start #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> [21:36:41] WARNING: src/learner.cc:767:  #> Parameters: { \"device\" } are not used. #>  #> mixgb null end  imputed.BMPHEAD <- show_var(   imputation.list = mixgb.data, var.name = \"BMPHEAD\",   original.data = nhanes3 ) imputed.BMPHEAD #>       m1   m2   m3 #>  1: 40.8 41.5 39.2 #>  2: 41.0 41.0 44.4 #>  3: 45.9 48.2 45.8 #>  4: 43.5 44.0 43.3 #>  5: 40.9 40.2 40.2 #>  6: 43.3 45.6 44.4 #>  7: 45.9 47.3 47.3 #>  8: 44.4 45.3 43.0 #>  9: 44.7 44.0 46.1 #> 10: 44.2 42.7 42.4 #> 11: 45.3 45.6 45.8 #> 12: 46.5 41.5 45.7 #> 13: 40.4 40.6 40.7 #> 14: 44.6 44.0 48.8 #> 15: 42.4 41.9 40.4 #> 16: 47.5 47.3 46.7 #> 17: 40.2 41.0 41.3 #> 18: 44.0 45.2 47.6 #> 19: 44.7 43.5 43.2 #> 20: 43.2 44.7 42.7 #> 21: 44.7 46.7 42.9 #> 22: 44.3 43.8 42.4 #> 23: 42.7 41.0 43.9 #> 24: 41.6 42.5 44.0 #> 25: 40.9 41.4 40.9 #> 26: 41.2 41.0 43.3 #> 27: 39.0 39.6 39.0 #> 28: 42.1 43.4 44.7 #> 29: 44.9 44.0 44.1 #> 30: 41.4 40.7 41.0 #> 31: 40.8 42.8 40.6 #> 32: 42.6 44.2 42.7 #>       m1   m2   m3"},{"path":"https://agnesdeng.github.io/mixgb/reference/sortNA.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort data by increasing number of missing values — sortNA","title":"Sort data by increasing number of missing values — sortNA","text":"Sort data increasing number missing values","code":""},{"path":"https://agnesdeng.github.io/mixgb/reference/sortNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort data by increasing number of missing values — sortNA","text":"","code":"sortNA(data)"},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"mixgb-142","dir":"Changelog","previous_headings":"","what":"mixgb 1.4.2","title":"mixgb 1.4.2","text":"Coming Soon!","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"miscellaneous-1-3-2","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"mixgb 1.3.2","text":"Improves package documentation regarding import xgb.save() xgb.load() XGBoost.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"compatibility-1-3-1","dir":"Changelog","previous_headings":"","what":"Compatibility","title":"mixgb 1.3.1","text":"Introduces new parameter device. Deprecates parameters gpu_id predictor. Sets tree_method = \"hist\" default, aligning XGBoost 2.0.0.","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"new-features-1-3-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"mixgb 1.3.1","text":"Models save JSON format using xgb.save(), method recommended XGBoost future compatibility. save.models.folder specified, return object mixgb() includes current imputed datasets, directories imputation models, relevant parameters. object can save using saveRDS() doesn’t directly contain models. Users can later load object R employ impute_new(object, newdata, ...) new data imputation.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"updates-1-2-1","dir":"Changelog","previous_headings":"","what":"Updates","title":"mixgb 1.2.1","text":"Includes URL published article.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"mixgb 1.2.0","text":"numeric integer factor logical Note: Users must manually convert character variables factors.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"mixgb 1.1.0","text":"Introduces default_params(), auxiliary function mixgb(), validate list XGBoost hyperparameters supplied user. simplifies hyperparameter modifications without requiring explicit specification default values.","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"bug-fixes-1-1-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"mixgb 1.1.0","text":"Addresses issues related PMM multiclass variables. Replaces ..density.. after_stat(density) plot_hist(). Replaces ..prop.. after_stat(prop) plot_bar().","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"mixgb-102","dir":"Changelog","previous_headings":"","what":"mixgb 1.0.2","title":"mixgb 1.0.2","text":"CRAN release: 2023-02-16","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"minor-changes-1-0-2","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"mixgb 1.0.2","text":"Adjusts examples use nthread = 2 comply CRAN policies.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"changes-in-default-settings-1-0-1","dir":"Changelog","previous_headings":"","what":"Changes in Default Settings","title":"mixgb 1.0.1","text":"Subsampling: subsample = 0.7. bootstrapping: bootstrap = FALSE.","code":""},{"path":[]},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"minor-bug-fixes-and-updates-0-1-1","dir":"Changelog","previous_headings":"","what":"Minor Bug Fixes and Updates","title":"mixgb 0.1.1","text":"Resolves minor issue createNA() function. ordinalAsInteger: Changes TRUE FALSE. max_depth: Changes 6 3. nrounds: Changes 50 100. bootstrap: Sets TRUE default.","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"mixgb-010","dir":"Changelog","previous_headings":"","what":"mixgb 0.1.0","title":"mixgb 0.1.0","text":"CRAN release: 2022-06-07","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"initial-release-0-1-0","dir":"Changelog","previous_headings":"","what":"Initial Release","title":"mixgb 0.1.0","text":"First version releases CRAN. Supports single multiple imputation. Offers customizable settings bootstrapping predictive matching. Provides visual diagnostics multiply imputed data.","code":""},{"path":"https://agnesdeng.github.io/mixgb/news/index.html","id":"notes-0-1-0","dir":"Changelog","previous_headings":"","what":"Notes","title":"mixgb 0.1.0","text":"Mac OSX users might face challenges multithreading mixgb xgboost requires OpenMP multi-core operations. details, please refer OpenMP Mac.","code":""}]
