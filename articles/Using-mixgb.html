<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>mixgb: Multiple Imputation Through XGBoost • mixgb</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="mixgb: Multiple Imputation Through XGBoost">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mixgb</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.5.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Imputing-newdata.html">Imputing newdata with a saved mixgb imputer</a></li>
    <li><a class="dropdown-item" href="../articles/Using-mixgb.html">mixgb: Multiple Imputation Through XGBoost</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/agnesdeng/mixgb/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>mixgb: Multiple Imputation Through XGBoost</h1>
                        <h4 data-toc-skip class="author">Yongshi
Deng</h4>
            
            <h4 data-toc-skip class="date">2025-05-09</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/agnesdeng/mixgb/blob/master/vignettes/Using-mixgb.Rmd" class="external-link"><code>vignettes/Using-mixgb.Rmd</code></a></small>
      <div class="d-none name"><code>Using-mixgb.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Mixgb offers a scalable solution for imputing large datasets using
XGBoost, subsampling and predictive mean matching. Our method utilizes
the capabilities of XGBoost, a highly efficient implementation of
gradient boosted trees, to capture interactions and non-linear relations
automatically. Moreover, we have integrated subsampling and predictive
mean matching to minimize bias and reflect appropriate imputation
variability. Our package supports various types of variables and offers
flexible settings for subsampling and predictive mean matching. We also
include diagnostic tools for evaluating the quality of the imputed
values.</p>
</div>
<div class="section level2">
<h2 id="impute-missing-values-with-mixgb">Impute missing values with <code>mixgb</code><a class="anchor" aria-label="anchor" href="#impute-missing-values-with-mixgb"></a>
</h2>
<p>We first load the <code>mixgb</code> package and the
<code>nhanes3_newborn</code> dataset, which contains 16 variables of
various types (integer/numeric/factor/ordinal factor). There are 9
variables with missing values.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/agnesdeng/mixgb" class="external-link">mixgb</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">nhanes3_newborn</span><span class="op">)</span></span>
<span><span class="co">#&gt; tibble [2,107 × 16] (S3: tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;  $ HSHSIZER: int [1:2107] 4 3 5 4 4 3 5 3 3 3 ...</span></span>
<span><span class="co">#&gt;  $ HSAGEIR : int [1:2107] 2 5 10 10 8 3 10 7 2 7 ...</span></span>
<span><span class="co">#&gt;  $ HSSEX   : Factor w/ 2 levels "1","2": 2 1 2 2 1 1 2 2 2 1 ...</span></span>
<span><span class="co">#&gt;  $ DMARACER: Factor w/ 3 levels "1","2","3": 1 1 2 1 1 1 2 1 2 2 ...</span></span>
<span><span class="co">#&gt;  $ DMAETHNR: Factor w/ 3 levels "1","2","3": 3 1 3 3 3 3 3 3 3 3 ...</span></span>
<span><span class="co">#&gt;  $ DMARETHN: Factor w/ 4 levels "1","2","3","4": 1 3 2 1 1 1 2 1 2 2 ...</span></span>
<span><span class="co">#&gt;  $ BMPHEAD : num [1:2107] 39.3 45.4 43.9 45.8 44.9 42.2 45.8 NA 40.2 44.5 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Head circumference (cm)"</span></span>
<span><span class="co">#&gt;  $ BMPRECUM: num [1:2107] 59.5 69.2 69.8 73.8 69 61.7 74.8 NA 64.5 70.2 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Recumbent length (cm)"</span></span>
<span><span class="co">#&gt;  $ BMPSB1  : num [1:2107] 8.2 13 6 8 8.2 9.4 5.2 NA 7 5.9 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "First subscapular skinfold (mm)"</span></span>
<span><span class="co">#&gt;  $ BMPSB2  : num [1:2107] 8 13 5.6 10 7.8 8.4 5.2 NA 7 5.4 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Second subscapular skinfold (mm)"</span></span>
<span><span class="co">#&gt;  $ BMPTR1  : num [1:2107] 9 15.6 7 16.4 9.8 9.6 5.8 NA 11 6.8 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "First triceps skinfold (mm)"</span></span>
<span><span class="co">#&gt;  $ BMPTR2  : num [1:2107] 9.4 14 8.2 12 8.8 8.2 6.6 NA 10.9 7.6 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Second triceps skinfold (mm)"</span></span>
<span><span class="co">#&gt;  $ BMPWT   : num [1:2107] 6.35 9.45 7.15 10.7 9.35 7.15 8.35 NA 7.35 8.65 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Weight (kg)"</span></span>
<span><span class="co">#&gt;  $ DMPPIR  : num [1:2107] 3.186 1.269 0.416 2.063 1.464 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "label")= chr "Poverty income ratio"</span></span>
<span><span class="co">#&gt;  $ HFF1    : Factor w/ 2 levels "1","2": 2 2 1 1 1 2 2 1 2 1 ...</span></span>
<span><span class="co">#&gt;  $ HYD1    : Ord.factor w/ 5 levels "1"&lt;"2"&lt;"3"&lt;"4"&lt;..: 1 3 1 1 1 1 1 1 2 1 ...</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">nhanes3_newborn</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; HSHSIZER  HSAGEIR    HSSEX DMARACER DMAETHNR DMARETHN  BMPHEAD BMPRECUM </span></span>
<span><span class="co">#&gt;        0        0        0        0        0        0      124      114 </span></span>
<span><span class="co">#&gt;   BMPSB1   BMPSB2   BMPTR1   BMPTR2    BMPWT   DMPPIR     HFF1     HYD1 </span></span>
<span><span class="co">#&gt;      161      169      124      167      117      192        7        0</span></span></code></pre></div>
<p>To impute this dataset, we can use the default settings. The default
number of imputed datasets is <code>m = 5</code>. Note that we do not
need to convert our data into dgCMatrix or one-hot coding format. Our
package will automatically convert it for you. Variables should be of
the following types: numeric, integer, factor or ordinal factor.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># use mixgb with default settings</span></span>
<span><span class="va">imputed.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mixgb.html">mixgb</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">nhanes3_newborn</span>, m <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="customize-imputation-settings">Customize imputation settings<a class="anchor" aria-label="anchor" href="#customize-imputation-settings"></a>
</h3>
<p>We can also customize imputation settings:</p>
<ul>
<li><p>The number of imputed datasets <code>m</code></p></li>
<li><p>The number of imputation iterations <code>maxit</code></p></li>
<li><p>XGBoost hyperparameters and verbose settings.
<code>xgb.params</code>, <code>nrounds</code>,
<code>early_stopping_rounds</code>, <code>print_every_n</code> and
<code>verbose</code>.</p></li>
<li><p>Subsampling ratio. By default, <code>subsample = 0.7</code>.
Users can change this value under the <code>xgb.params</code>
argument.</p></li>
<li><p>Predictive mean matching settings <code>pmm.type</code>,
<code>pmm.k</code> and <code>pmm.link</code>.</p></li>
<li><p>Whether ordinal factors should be converted to integer
(imputation process may be faster)
<code>ordinalAsInteger</code></p></li>
<li><p>Whether or not to use bootstrapping
<code>bootstrap</code></p></li>
<li><p>Initial imputation methods for different types of variables
<code>initial.num</code>, <code>initial.int</code> and
<code>initial.fac</code>.</p></li>
<li><p>Whether to save models for imputing newdata
<code>save.models</code> and <code>save.vars</code>.</p></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Use mixgb with chosen settings</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  max_depth <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  subsample <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>  nthread <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  tree_method <span class="op">=</span> <span class="st">"hist"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">imputed.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mixgb.html">mixgb</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">nhanes3_newborn</span>, m <span class="op">=</span> <span class="fl">10</span>, maxit <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  ordinalAsInteger <span class="op">=</span> <span class="cn">FALSE</span>, bootstrap <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  pmm.type <span class="op">=</span> <span class="st">"auto"</span>, pmm.k <span class="op">=</span> <span class="fl">5</span>, pmm.link <span class="op">=</span> <span class="st">"prob"</span>,</span>
<span>  initial.num <span class="op">=</span> <span class="st">"normal"</span>, initial.int <span class="op">=</span> <span class="st">"mode"</span>, initial.fac <span class="op">=</span> <span class="st">"mode"</span>,</span>
<span>  save.models <span class="op">=</span> <span class="cn">FALSE</span>, save.vars <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  xgb.params <span class="op">=</span> <span class="va">params</span>, nrounds <span class="op">=</span> <span class="fl">200</span>, early_stopping_rounds <span class="op">=</span> <span class="fl">10</span>, print_every_n <span class="op">=</span> <span class="fl">10L</span>, verbose <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="tune-hyperparameters">Tune hyperparameters<a class="anchor" aria-label="anchor" href="#tune-hyperparameters"></a>
</h3>
<p>Imputation performance can be affected by the hyperparameter
settings. Although tuning a large set of hyperparameters may appear
intimidating, it is often possible to narrowing down the search space
because many hyperparameters are correlated. In our package, the
function <code><a href="../reference/mixgb_cv.html">mixgb_cv()</a></code> can be used to tune the number of
boosting rounds - <code>nrounds</code>. There is no default
<code>nrounds</code> value in <code>XGBoost,</code> so users are
required to specify this value themselves. The default
<code>nrounds</code> in <code><a href="../reference/mixgb.html">mixgb()</a></code> is 100. However, we
recommend using <code><a href="../reference/mixgb_cv.html">mixgb_cv()</a></code> to find the optimal
<code>nrounds</code> first.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>max_depth <span class="op">=</span> <span class="fl">3</span>, subsample <span class="op">=</span> <span class="fl">0.7</span>, nthread <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">cv.results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mixgb_cv.html">mixgb_cv</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">nhanes3_newborn</span>, nrounds <span class="op">=</span> <span class="fl">100</span>, xgb.params <span class="op">=</span> <span class="va">params</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">cv.results</span><span class="op">$</span><span class="va">evaluation.log</span></span>
<span><span class="co">#&gt;      iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std</span></span>
<span><span class="co">#&gt;     &lt;num&gt;           &lt;num&gt;          &lt;num&gt;          &lt;num&gt;         &lt;num&gt;</span></span>
<span><span class="co">#&gt;  1:     1       5.6243200     0.01725215      5.6242119    0.07519387</span></span>
<span><span class="co">#&gt;  2:     2       3.9873035     0.01041157      3.9927615    0.07643722</span></span>
<span><span class="co">#&gt;  3:     3       2.8486556     0.01272129      2.8524742    0.07121946</span></span>
<span><span class="co">#&gt;  4:     4       2.0598481     0.01185795      2.0647573    0.07232445</span></span>
<span><span class="co">#&gt;  5:     5       1.5196993     0.01574637      1.5293888    0.07642496</span></span>
<span><span class="co">#&gt;  6:     6       1.1555977     0.01745843      1.1770621    0.08059807</span></span>
<span><span class="co">#&gt;  7:     7       0.9218320     0.02051193      0.9529445    0.09058948</span></span>
<span><span class="co">#&gt;  8:     8       0.7719014     0.02131583      0.8155824    0.09712346</span></span>
<span><span class="co">#&gt;  9:     9       0.6840419     0.02121464      0.7364341    0.10134552</span></span>
<span><span class="co">#&gt; 10:    10       0.6319835     0.02324912      0.6910356    0.10442807</span></span>
<span><span class="co">#&gt; 11:    11       0.6013581     0.02490061      0.6666511    0.10520464</span></span>
<span><span class="co">#&gt; 12:    12       0.5835209     0.02668848      0.6527954    0.10396770</span></span>
<span><span class="co">#&gt; 13:    13       0.5702095     0.02693038      0.6454456    0.10355826</span></span>
<span><span class="co">#&gt; 14:    14       0.5594641     0.02447102      0.6417038    0.10258203</span></span>
<span><span class="co">#&gt; 15:    15       0.5540570     0.02305729      0.6379671    0.10187290</span></span>
<span><span class="co">#&gt; 16:    16       0.5504931     0.02227745      0.6371141    0.10272587</span></span>
<span><span class="co">#&gt; 17:    17       0.5421563     0.02074779      0.6349845    0.10188686</span></span>
<span><span class="co">#&gt; 18:    18       0.5395515     0.02107327      0.6333410    0.10147670</span></span>
<span><span class="co">#&gt; 19:    19       0.5342802     0.01954349      0.6361272    0.09976709</span></span>
<span><span class="co">#&gt; 20:    20       0.5309925     0.01900489      0.6362062    0.10066105</span></span>
<span><span class="co">#&gt; 21:    21       0.5277205     0.01834704      0.6367092    0.09997261</span></span>
<span><span class="co">#&gt; 22:    22       0.5255634     0.01808838      0.6369874    0.09927022</span></span>
<span><span class="co">#&gt; 23:    23       0.5218592     0.01784562      0.6380108    0.09842193</span></span>
<span><span class="co">#&gt; 24:    24       0.5177798     0.01593962      0.6380967    0.09938728</span></span>
<span><span class="co">#&gt; 25:    25       0.5133888     0.01539523      0.6387354    0.09861629</span></span>
<span><span class="co">#&gt; 26:    26       0.5103064     0.01560169      0.6386598    0.09888282</span></span>
<span><span class="co">#&gt; 27:    27       0.5081871     0.01583676      0.6400786    0.09894321</span></span>
<span><span class="co">#&gt; 28:    28       0.5058566     0.01618987      0.6401878    0.09903052</span></span>
<span><span class="co">#&gt;      iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std</span></span>
<span><span class="va">cv.results</span><span class="op">$</span><span class="va">response</span></span>
<span><span class="co">#&gt; [1] "BMPWT"</span></span>
<span><span class="va">cv.results</span><span class="op">$</span><span class="va">best.nrounds</span></span>
<span><span class="co">#&gt; [1] 18</span></span></code></pre></div>
<p>By default, <code><a href="../reference/mixgb_cv.html">mixgb_cv()</a></code> will randomly choose an
incomplete variable as the response and build an XGBoost model with
other variables as explanatory variables using the complete cases of the
dataset. Therefore, each run of <code><a href="../reference/mixgb_cv.html">mixgb_cv()</a></code> will likely
return different results. Users can also specify the response and
covariates in the argument <code>response</code> and
<code>select_features</code> respectively.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mixgb_cv.html">mixgb_cv</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">nhanes3_newborn</span>, nfold <span class="op">=</span> <span class="fl">10</span>, nrounds <span class="op">=</span> <span class="fl">100</span>, early_stopping_rounds <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  response <span class="op">=</span> <span class="st">"BMPHEAD"</span>, select_features <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"HSAGEIR"</span>, <span class="st">"HSSEX"</span>, <span class="st">"DMARETHN"</span>, <span class="st">"BMPRECUM"</span>, <span class="st">"BMPSB1"</span>, <span class="st">"BMPSB2"</span>, <span class="st">"BMPTR1"</span>, <span class="st">"BMPTR2"</span>, <span class="st">"BMPWT"</span><span class="op">)</span>, xgb.params <span class="op">=</span> <span class="va">params</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">cv.results</span><span class="op">$</span><span class="va">best.nrounds</span></span>
<span><span class="co">#&gt; [1] 20</span></span></code></pre></div>
<p>Let us just try setting
<code>nrounds = cv.results$best.nrounds</code> in <code><a href="../reference/mixgb.html">mixgb()</a></code>
to obtain 5 imputed datasets.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">imputed.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mixgb.html">mixgb</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">nhanes3_newborn</span>, m <span class="op">=</span> <span class="fl">5</span>, nrounds <span class="op">=</span> <span class="va">cv.results</span><span class="op">$</span><span class="va">best.nrounds</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="inspect-multiply-imputed-values">Inspect multiply imputed values<a class="anchor" aria-label="anchor" href="#inspect-multiply-imputed-values"></a>
</h2>
<p>The <code>mixgb</code> package used to provide a few visual
diagnostics functions. However, we have moved these functions to the
<code>vismi</code> package, which provides a wide range of visualisation
tools for multiple imputation.</p>
<p>For more details, please check the <code>vismi</code> package on
GitHub <a href="https://github.com/agnesdeng/vismi" class="external-link">Visualisation Tools
for Multiple Imputation</a>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Yongshi Deng.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
